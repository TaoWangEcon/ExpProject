\documentclass[]{article}
\usepackage{amsmath}
\usepackage{adjustbox}

%opening
\title{Testing Theories of Expectation Formation using Probabilistic Forecasts}
\author{Tao Wang}

\begin{document}

\maketitle

\section{Introduction}


The theories on how different agents form expectations have proliferated over the past decade. On one hand, these theories built upon different micro foundations produce some similar macro patterns. For instance, the notion of information rigidity, or expectation rigidity could be micro founded by many different theories, but mostly generate sluggish response to new information.  

On the other hand, however, there are important and subtle differences in testable predictions from these theories for both individual forecasts and aggregate moments of the forecasts. My goal of this exercise is to derive the testable predictions based on various theories, and utilize the probablistic questions from both professional forecasters survey and household survey to test them. 

The potential contribution lies in the extra insights I may get from using probablistic questions.\footnote{For an insightful survey on the importance of measuring subjective expectations using probablistic surveys, see \cite{manski2004measuring}.} One obvious advantage of density expectations compared to point one is availability of higher moments, i.e. variance of the forecast indicates the dispersion of the forecasts. Along time dimension, the dynamics of conditional relative likelihood is a useful indicator of information gain or forecasting efficiency. Besides, as in a typical signal-extraction model, the prediction that new information reduce conditional variance can be tested only using probability distributions. Although the detailed implementation of these tests involves technical difficulties, the ideas are quite clear.  Lastly, with second moments in individual level expectations, we are allowed to potentialy explore the heterogeneity across agents within one theory. For instance, sticky information typically assume a posson update rate for all agents in the economy. This is partly due to the fact that available data only allows us to recover single parameter of regidity instead of inter-group heterogeneity.  

\section{Theories of Expectation Formation}

\subsection{Definition of moments}

An agent $i$ is forming expectations about a stochastic variable $y^i_{t+h}$. The supscript $i$ can be dropped if it is an aggregate (i.e. inflation) variable instead of individual specific  (i.e. household income or house value). This paper focuses on forecasting of aggregate variables, in particular, inflation. So we can simply denote the variable as $y_{t+h}$. To put it another way, all agents are foreasting the same object. \footnote{Only in the context of forecasting aggregate variable, it is meaningful to study the average expectations and disagreements across agents.}

Denote $ f_{i,t+h|t}$ as agent i's $h$-period-ahead density forecast. $ f_{i,t+h|t}$ is the conditional density of $y_{i,t+h}$ given the information set $I_{i,t}$ available at time $t$. 

$$f_{i,t+h|t} \equiv f_{i,t}(y_{t+h}|I_{i,t})$$


$I_{i,t}$ is the information set available for individual $i$ at time t. The information set can be  agent specific, thus it has subscript $i$.  The specific content contained in $I_t$ varies from different models of expectation. For instance, sticky expectation and rational inattention literature all assume that agents are not able to update new information instataneously. So the information set may not contain the most recent realization of the variable of forecast $y_t$. \footnote{Given the same information set available to agents, different theories may also differ in the underlying models each agent use to form the conditional density of the variables by agent $i$. Examples of such include multi-prior or model uncertainty. \cite{xx}. }

Accordingly, h-period ahead mean forecast at $t$, denoted as $ y_{i,t+h|t}$, is the conditional expectation of $y_{t+h}$ by the agent $i$. 

$$y_{i,t+h|t} \equiv E_{i,t}(y_{t+h}) =\int f_{i, t+h|t} d y_{t+h}$$

Similarly, individual forecasting variance $\sigma_{i,t+h|t}$, hereafter termed as indiviual uncertainty in this paper, is the conditional variance.

$$\sigma^2_{i,t+h|t} \equiv Var_{i,t}( y_{t+h} )$$

Individual forecast error $FE_{i,t+h|t}$ is the difference of ex post realized value of $y_{t+h}$ and individual foreacast at time $t$. 

$$FE_{i,t+h|t} = y_{i,t+h|t} - y_{t+h}$$

The population analogues of individual mean forecast, uncertainty and forecast errors are simply the average of the individual moments taken across agents. Denote them as $\bar y_{t+h|t}$, $\bar \sigma^2_{t+h|t}$, and $\overline{FE}_{t+h|t}$, respectively. Hereafter, they are termed as population mean forecast, population uncertainty and population forecast error, respectively. In addition, disagreements is defined as the cross-sectional variance of mean forecasts of individual agents.  Denote it as $\overline{Var}_{t+h|t}(y_{i,t+h|t}) $. To simplify notation, let us directly call it $\overline{Disg}_{t+h|t}$.  \footnote{This is the same termiology used by \cite{xx}.}

In summary, we have 3 individual moments and 4 population moments listed in below. 

\begin{table}[]
	\centering
		\caption{Definition and Notation of Moments}
	\begin{tabular}{ll}

		\hline 
		Individual Moments                                  & Population Moments                             \\
		\hline 
	Mean orecast: $y_{i,t+h|t}$                   & Average forecast: $\bar y_{t+h|t}$                   \\
		Forecast error: $FE_{i,t+h|t}$ & Average forecast error: $\overline{FE}_{t+h|t}$ \\
		Uncertainty: $\sigma^2_{i,t+h|t}$         & Average uncertainty:  $\bar \sigma^2_{i,t+h|t}$ \\
		& Disagreements:  $\overline{Disg}_{t+h|t}$       \\
		\hline 
	\end{tabular}
\end{table}

Finally, we assume the underlying true process of $y_{t}$ is $AR(1)$ with persistency parameter $0<\rho <1$ and i.i.d. shock $\omega_t$. 

$$y_{t+1} = \rho y_t + \omega_t$$

$$\omega_t \sim N(0,\sigma^2_{\omega})$$

\subsection{Full-information rational expectation benchmark }

In the full information rational expectation (FIRE) benchmark,  we assume all agents perfectly observe $y_t$ at time $t$ and understand the true process of $y$. Therefore, individual forecast is $\rho^h y_t $. This is also shared by all agents. Therefore, it is also equal to average forecast. 

Both individual and population forecast errors are simply the realized shocks between $t+1$ to $t+h$.  

$$\overline{FE}_{i,t+h|t} = \sum^{h-1}_{s=1} \rho^s \omega_{t+h-s}$$ It is easy to see that the forecast error is orthogonal to information available till time $t$. This provides the a well known null hypothesis of FIRE. \cite{xx}

The second testable null hypothesis of FIRE here is that forecast errors at two points of time $h$ or more periods apart are not serially correlated. This is not the case within $h$ periods as the realized shocks in overlapping periods enter both forecast errors. 

$$Cov(\overline{FE}_{t+h|t}, \overline{FE}_{t+s+h|t+s}) = 0 \quad \forall s \geq h$$

The predictions holds at both individual and population levels. 

Another hypothesis test of FIRE relies upon disagreements. \footnote{For instance, \cite{mankiw2003disagreement} documents substantial time-varying disagreements about future inflation using consumers and professional forecasters' survey. } As agents perfect update the same information, there is no disagreements at any point of the time. 

$$\overline{Disg}_{t+h|t}=0 \quad \forall t$$

A corollary is that disagreements do not respond to realized shocks any any point of the time.  Empricial tests of this kind include \cite{xx}.\cite{xx} etc. 

In addition to forecast error and disagreements, FIRE also predicts that all individual shares the same degree of uncertainty. The same degree of uncertainty simply comes from uncertainty about future unrealized shocks between $t$ and $t+h$. In \cite{}'s termology, not only all agents agree about the mean forecast, but also agree about the uncertainty according to FIRE. 

$$\bar \sigma^2_{t+h|t} = \sum^{h}_{s=1}\rho^{2s} \sigma^2_{\omega}$$

The time series pattern of uncertainty according to FIRE is less obvious. Weather it is time variate depends on if the variance of the shocks $\omega_t$ is time varying. Although in our baseline case we make such an assumption, in general it may not be true. 

It turns out, however, the serial correlation of uncertainty across different horizons of forecasting does follow testable pattern according to FIRE. In particular, consistent with our current notation, let us denote the forecast of $y_{t+h}$ over horizon of $h-k$ as $y_{t+h|t+k} \quad \forall k =0,1...h$. 

$$\bar \sigma^2_{t+h|t+k} = \sum^{h-k}_{s=1}\rho^{2s} \sigma^2_{\omega}$$

As the forecasting horizon decreases relative to a given future point of time, there is a pure efficiency gain or reduction in uncertainty as more and more shocks have realized. So the uncertainty should drop unambigously. Quanlitatively, this implies that $\bar \sigma^2_{t+h|t+k} < \bar \sigma^2_{t+h|t}$ $\forall 1<k\leq h$. 

Compared to other null hypotheses discussed above, this is a weaker test. It is true that rational foreacsting implies reduction in uncertainty with shorter horizon. But there is no direct test if the drop in uncertainty is efficient enough so as to be consistent with FIRE. 

\subsection{Sticky Expectation}

*****************************************************

Agent does not update information instantaneously, instead at a Possion rate $\lambda$. Specificaly, at any point of time $t$, the agent learns about the up-to-date realization of $y_t$ with probability of $\lambda$; otherwise, it forms the expectation based on the most recent up-to-date realization of $y_{t-\tau}$, where $\tau$ is the time experienced since previous update. 

\subsubsection{Individual moments} 

For an individual whose most recent update occurs at $\tau$ period before, $I_{i,t|t-\tau} = I_{i,t-\tau} = y_{t-\tau}$. Thus

$$E_{i,t|t-\tau}(y_{t+h}|I_{i,t}) = E_{i,t}(i,y_{t+h}|y_{t-\tau}) = \rho^{h+\tau} y_{t-\tau}$$

$$Var_{i,t|t-\tau}(y_{t+h}|I_{i,t}) = Var_{i,t}(y_{t+h}|y_{t-\tau}) = \sum^{h+\tau}_{s=0}\rho^{2s} \sigma^2_{\omega}$$

$Var_{i,t|t-\tau}(y_{t+h}|_{i,t})$ increases as $\tau$ increases. The model collapses to full-information rational expectation if $\tau=0$ for all individuals. 

Now, we turn to the case when agent updates infrequently. 

\begin{itemize}
\item When the update happens, the variance responds substantially.  

$$Var_{i,t}(y_{t+h}|y_t) - Var_{i,t|t-\tau}(y_{t+h}|y_{t-\tau}) = \sum^{h}_{s=0}\rho^{2s} \sigma^2_{\omega} - \sum^{h+\tau}_{s=0}\rho^{2s} \sigma^2_{\omega} = \sum^{\tau}_{s=0} \rho^{2s}\sigma^2_{\omega}$$

\item When the update does not happen, the variance responds little. 

$$Var_{i,t|t-\tau-1}(y_{t+h}|y_{t-\tau-1}) - Var_{i,t|\tau}(y_{t+h}|y_{t-\tau}) = \sigma^2_{\omega}$$

At individual level, it is hard to recover the information rigidity parameter $\lambda$ directly. One testable prediction of information rigidity is that the change in forecast variance varies substantially depending on if updated or not. The longer period for which the agent stays unupdated(greater $\tau$), the bigger the change is in the forecasting variance. 

However, the difference in average responses in variance to new information may speak to potential heterogeneity in information rigidity. According to the theory above, higher information rigidity implies high volatility of variance responses.  
\end{itemize}

\subsubsection{Population moments} 
	
\begin{enumerate}	
\item Average forecast

The mean forecast across population is a weighted average of past rational expectations 

\begin{eqnarray}
\begin{aligned}
\bar E_t(y_{t+h}) & = \lambda \underbrace{E_t(y_{t+h})}_{\textrm{rational expectation at t}} + (1-\lambda) \underbrace{\bar E_{t-1}{y_{t+h}}}_{\textrm{average expectation at} t-1} \\
& = \lambda E_t(y_{t+h}) + (1-\lambda) (\lambda E_{t-1}(y_{t+h})+ (1-\lambda) \bar E_{t-2}(y_{t+h}))... \\
& = \lambda \sum^{\infty}_{s=0} (1-\lambda)^s E_{t-s}(y_{t+h}) \\
& = \lambda \sum^{\infty}_{s=0} (1-\lambda)^s \rho^{s+h}y_{t-s}
\end{aligned}
\end{eqnarray}

The change in average forecast is 

\begin{eqnarray}
\begin{aligned}
\Delta \bar E_t(y_{t+h})&  = (1-\lambda) \Delta \bar E_{t-1}(y_{t+h}) + \lambda (E_t(y_{t+h}) - E_{t-1}(y_{t+h})) \\ 
& = (1-\lambda) \Delta \bar E_{t-1}(y_{t+h}) + \lambda \rho^h \omega_t 
\end{aligned}
\end{eqnarray}

This implies the change in average forecast is serially correlated, depending on the information rigidity, i.e. lower $\lambda$ implies higher serial correlation. Also lower $\lambda$ implies the expectation underreact to the shocks at $t$. 

\item Cross-sectional disagreements

According to information rigity model, if everyone is instantaneously udpated, there should not be disagreements. In general, the dispersion in forecasting is non-zero because of different lags in updating. One can also derive variance of forecasts across agents at time $t$ 

\begin{eqnarray}
\begin{aligned}
Var_t(E_{i,t}(y_{t+h}) ) & = \lambda \sum^{\infty}_{\tau=0} (1-\lambda)^{\tau} (E_{t|t-\tau}(y_{t+h}) - \bar E_t(y_{t+h}))^2  
\end{aligned}
\end{eqnarray}

From time $t$ to $t+1$, the change in dispersion comes from two sources. One is newly realized shock at time $t+1$. The other component is from people who did not update at time $t$ and update at time $t+1$.  

\begin{eqnarray}
\begin{aligned}
\Delta Var_{t+1}(E_{i,t+1}(y_{t+h})) = \textrm{change due to new updaters} + \textrm{shock at time } t+1 
\end{aligned}
\end{eqnarray}


Notice the change is positive, meaning the dispersion rises in response to a shock. Importantly, the increase is the same regardless of the realization of the shock. 

More generally, we can derive the impulse response of dispersion at time $t+j$ to a shock that realized at $t$. 

\begin{eqnarray}
\rho^{2(h+j)} (1-\lambda^{j+1})\lambda^{j+1} \omega^2_t
\end{eqnarray}


A shock increases the disagreements across agents and then it gradually returns to its steady state level. 

\item Average variance

Since we have individual level variance, we can also derive average variance of the population. Taking the average of variance across individual agents at time $t$. Here I use the $\bar{}$ to represent population mean of variance. 

\begin{eqnarray}
\begin{aligned}
\bar Var_{t}(y_{t+h}) & = \sum^{+\infty}_{\tau =0} \underbrace{\lambda (1-\lambda)^\tau}_{\text{fraction who does not update until }t-\tau} \underbrace{Var_{t|t-\tau}(y_{t+h})}_{\text{ Variance of most recent update at }t-\tau} \\
& = \sum^{+\infty}_{\tau =0} \lambda (1-\lambda)^\tau \sum^{h+\tau}_{s=0}\rho^{2s} \sigma^2_{\omega}
\end{aligned}
\end{eqnarray}

Correspondingly, the change in average uncertainty will be 


\begin{eqnarray}
\begin{aligned}
\Delta \bar Var_{t}(y_{t+h}) & = \sum^{+\infty}_{\tau =0} \lambda (1-\lambda)^\tau \sum^{h+\tau}_{s=0}\rho^{2s} \sigma^2_{\omega} - \sum^{+\infty}_{\tau =0} \lambda (1-\lambda)^\tau \sum^{h+\tau}_{s=0}\rho^{2s} \sigma^2_{\omega} = 0  
\end{aligned}
\end{eqnarray}

An information rigidity model based on fixed Poisson update rate predicts that the average variance does not change over time. This can be tested.

\end{enumerate}


\subsubsection{Summary of predictions of information rigidity}

\begin{itemize}
\item Individual expectation may or may not change depend upon if updating. 
\item Individual variances changes non-monotonically depending on if updating. Always increase with arrival of new information. 
\item Population mean of forecast responds with lags. Change is serially correlated. 
\item Population dispersion of forecasts rise in response to new shocks and return to steady state level gradually. 
\item Population average variance does not change over time. 
\end{itemize}

\subsection{Noisy information}

A class of so-called noisy information model describes the expectation formation as a process extracting or filtering true fundamental state variable $y_t$ from a sequence of realized signals. The starting assumption is that agent cannot observe the true variable perfectly. Unlike information rigidity model, it is assumed that agents keep track of the realizations of the signals instantaneously all the time. 

We assume agent $i$ observe two signals $s^{pb}$ and $s^{pr}_i$, with $s^{pb}$ being public signal common to all agents, and $s^{pr}_i$ private signals being individual specific. The generating process of two signals are 

\begin{eqnarray}
\begin{aligned}
s^{pb}_t = y_t + \epsilon_t, \quad \epsilon_t \sim N(0,\sigma^2_\epsilon)\\ 
s^{pr}_{i,t} = y_t + \xi_{i,t} \quad \xi_{i,t} \sim N(0,\sigma^2_\epsilon)
\end{aligned}
\end{eqnarray}

We can stack the two signals into one vector $s_{i,t} = [s^{pb}_t,s^{pr}_{i,t}]'$ and $v_{i,t}= [\epsilon_t,\xi_{i,t}]'$. So in a compact form, it can be written as


\begin{eqnarray}
\begin{aligned}
s_{i,t} = H y_{t} + v_{i,t} \\
\text{where } & H=[1,1]' \quad \\
\end{aligned}
\end{eqnarray}


In our general framework, the noisy information implies that the information set $I_{i,t}$ available to individual $i$ at time $t$ only includes past and recent realizations of the signals. The individual density forecast of $y_{t+h}$ is

$$\widehat f_{i,t}(y_{t+h}|I_{i,t}) = \widehat  f_{i,t}(y_{t+h}|s_{i,t},s_{i,t-1}...) \equiv \widehat  f_{i,t|t}(y_{t+h})$$


We use $t|k$ to denote the moments at time t based on information(signals) till time $k$. 


Then we are ready to apply Kalman Filter in this context. The posterior distribution of $y_{t}$ after seeing all signals till $t$ is 

\begin{eqnarray}
\widehat  f_{i,t|t}(y_{t+h})  \sim  N(E_{i,t|t}(y_{t+h}), Var_{i,t|t}(y_{t+h}))
\end{eqnarray}

where the expectation and variances are functions of noisiness of signals and fundamentals. The expectation also depends on the realized values. But this is not the case for variance. 

\subsubsection{Individual moments }

\begin{enumerate}
	
\item Expectation

Now any agent trying to forecast future variables will have to form her expectation of the contemporaneous state variable, $E_{i,t|t}(y_t)$. Then the best h-period ahead forecast is simply iterated h periods forward based on the AR(1) process.  

Thus, we first work out $E_{i,t|t}(y_t)$.  

\begin{eqnarray}
\begin{aligned}
E_{i,t|t}(y_{t}) 
& =  \underbrace{E_{i,t|t-1}(y_{t})}_{\text{prior}} + P \underbrace {(s_{i,t|t}-s_{i,t|t-1})}_{\text{innovations to signals}} \\
& = (1-PH) E_{i,t|t-1}(y_{t}) + Ps_{i,t} \\
& = (1-PH) E_{i,t|t-1}(y_{t}) + PH y_{i,t} + P v_{i,t} \\
\text{where the Kalman gain }  & P = [P_\epsilon,P_\xi]= \Sigma^y_{i,t|t-1} H(H'\Sigma^y_{i,t|t-1} H + \Sigma^v)^{-1} \\
\text {where } & \Sigma^y_{i,t|t-1} \text{ is the variance of } y_t \text{ based on prior belief}\\
\text {and } & \Sigma^v =  \left[ \begin{matrix} 
  \sigma^2_{\epsilon} &  0 \\ 0 & \sigma^2_\xi \end{matrix}\right] 
\end{aligned}
\end{eqnarray}

The h-period ahead forecast is 

\begin{eqnarray}
\begin{aligned}
E_{i,t|t}(y_{t+h}) & = \rho^{h}E_{i,t|t}(y_{t+h}) 
\end{aligned}
\end{eqnarray}


Individual forecast partially responds to new signals, i.e. $P<1$. $P=1$ is a special case when both signals are perfect thus $\Sigma^v = 0$, then the formula collapses to full rational expectation. 

Now, the rigidity parameter is governed by $1-PH$ with multiple signals. It is a function of variance of $y$ from the prior of previous period and noisiness of the signals. Therefore, it is time variant as the variance is updated by the agent each period.  


There are a few important distinctions between noisy information and sticky expectation. 

$\bullet$  First, the persistence of expectation exists at individual level. There is serially correlation between $E_{i|t|t}(y_t)$ and $E_{i,t|t-1}(y_{t})$, or more generally, between $E_{i,t|t}(y_{t+h})$ and $E_{i,t|t-1}(y_{t+h})$. This pattern can be only observed from population moments according to sticky expectation models. 


To see this, the change in individual forecast from $t-1$ to $t$ is 

\begin{eqnarray}
\begin{aligned}
\Delta E_{i,t|t}(y_{t+h}) & = \underbrace{\rho^h (1-PH)\Delta E_{i,t-1|t-1}(y_{t})}_{\text{Lagged response}} + \underbrace{\rho^hPH \Delta y_{i,t} + \rho^h P\Delta v_{i,t}}_{\text{Shocks to signals}}\\
\end{aligned}
\end{eqnarray}

The serial correlation is $\rho^h(1-PH)$, it does not only depend on $PH$, but also the forecast horizon $h$. Therefore, one testable assumption is to see auto regression of change in forecast to see if the coefficient depends on horizon. 

$\bullet$  Second, the expectation adjusts in each period as long as there is new information. In sticky expectation, however, the expectation adjusts only when the agent updates. 

\item Variance

The posterior variance at time $t$ is a linear function of prior variance and variance of signals. 

\begin{eqnarray}
\begin{aligned}
\Sigma^y_{i,t|t} = \Sigma^y_{i,t|t-1} - \Sigma^y_{i,t|t-1} H'(H \Sigma^y_{i,t-1} H' +\Sigma^v) H \Sigma^y_{i,t|t-1} 
\end{aligned}
\end{eqnarray}

There are a few important properties in the variance. 

- First, it does not depend on the realizations of the signal. 

- Second, it decreases unambigously from $t-1$ to $t$. To see this 

\begin{eqnarray}
\Sigma^y_{i,t|t} - \Sigma^y_{i,t|t-1} = - \Sigma^y_{i,t|t-1} H'(H \Sigma^y_{i,t-1} H' +\Sigma^v) H \Sigma^y_{i,t|t-1} <0
\end{eqnarray}

These two properties carry through to the h-period ahead forecast as well. As the forecast variance is the following 

\begin{eqnarray}
Var_{i,t|t} (y_{t+h}) = \rho^{2h} \underbrace{Var_{i,t}(y_{t})}_{\Sigma_{i,t|t}} + \sum^{h}_{s=0}\rho^{2s} \sigma^2_{\omega}
\end{eqnarray}


\begin{eqnarray}
\Delta Var_{i,t|t} (y_{t+h}) = \rho^{2h}\Delta \Sigma_{i,t|t} - \rho^{2h} \sigma^2_{\omega}
\end{eqnarray}

From $t$ to $t+1$, when $h\geq 1$, the decline in variance come from two sources. The first source is the pure gain from the new signals, i.e. $\Delta \Sigma^y_{i,t|t}$. It is scalled by the factor $\rho^{2h}$. The second source is present in full information rational expectation model: as time goes from $t-1$ to $t$, there is a reduction of uncertainty about $\omega_t$.

\end{enumerate}

\subsubsection{Population moments}

\begin{enumerate}
	
\item Average forecast


\begin{eqnarray}
\begin{aligned}
\bar E_{t|t} (y_{t+h}) & = \rho^h [(1-PH) \underbrace{\bar E_{t-1}(y_{t+h})}_{\text{Average prior}} + P \underbrace{\bar s_{t}}_{\text{Average Signals}}] \\
& = (1-PH) \bar E_{t-1}(y_{t+h}) + P [\epsilon_t, 0]' \\
& = (1-PH) \bar E_{t-1}(y_{t+h}) + P \epsilon_t
\end{aligned}
\end{eqnarray}

\item Change in average forecast

\begin{eqnarray}
\begin{aligned}
\Delta \bar E_t|t (y_{t+h}) & = \rho^h (1-PH) \Delta \bar E_{t-1}(y_{t+h}) + \rho^h P \Delta \epsilon_t
\end{aligned}
\end{eqnarray}


Same to the individual forecast, the change in average forecasts has serial correlation with the same auto regression parameter $\rho^h(1-PH)$.  

\item Cross-sectional disagreements

In this model, the only disagreements across agents come from the difference in realized private signals. Therefore, in short-cut, the disagreements are 

\begin{eqnarray}
\begin{aligned}
Var_t(y_{t+h}) & = E((E_{i,t|t}(y_{t+h}) - \bar E_t(y_{t+h}))^2) \\
& = \rho^{2h} P^2_\xi \sigma^2_\xi  
\end{aligned}
\end{eqnarray}


Several properties. 

$\bullet$ First, the disagreements increase with the forecast horizon. 
$\bullet$  Second, the disagreements depends on noisiness private signals, but not on that of public signals and the variance of the true variable $y$. 
$\bullet$  Third, similar to sticky expectation model, the disagreements also increase with the rigidity parameter $P$ in this model.


\item Change in disagreements


\begin{eqnarray}
\begin{aligned}
\Delta Var_t(y_{t+h}) & = \rho^{2h}(1-\rho^2) P^2_\xi \sigma^2_\xi >0
\end{aligned}
\end{eqnarray}

The disagreements increase as time goes from $t-1$ to $t$. Also, as the time approaches $t+h$, the disagreements increase. This seems counterintuitive. But the reason is that here the disagreenments always exist simply because agents receive private signals, this disagreements is actually amplified as time goes forward. 

\item Average variance

Since the variance does not depend on signals and the precision is the same aross the agents, average variance is equal to the variance of each individual. 

\begin{eqnarray}
\begin{aligned}
\bar Var_t (y_{t+h}) = \bar \Sigma^y_t
\end{aligned}
\end{eqnarray}

Also, same as the individual variance, the variance unambiguiously drop as time goes by. 

\begin{eqnarray}
\Delta Var_t(y_{t+h}) < 0 
\end{eqnarray}

\subsubsection{Summary of predictions from noisy information}

$\bullet$  Invididual expectation adjusts in each period, but only partially adjusts to new information. \\
$\bullet$ Unlike sticky expectation, slugishness in adjustment or serial correlation of adjustment exists in individual level. The correlation parameter decreases with forecast horizon, which is not the case in sticky expectation.\\
$\bullet$  Individual variance unambiguously drops each period as one approaches the period of realization. In sticky expectation, it increases regardless of updating or not. \\ 
$\bullet$  Population average forecast partially adjusts to news and has serial correlation as the individual level. \\
$\bullet$  Population disagreements rise in each period as time approaches the period of realization. Disagreetments will never be zero. \\
$\bullet$  Average variance declines unambiguously each period. 
\end{enumerate}



\subsection{Other Theories}

\begin{enumerate}
\item Rational inattention. 
\begin{itemize}
	\item Chris Sim's model.\cite{sims2003implications} Information serves the role of uncertainty reduction measured by relative entropy. Agents optimally trade off the fixed cost of being attentative versus the gain from uncertainty gain.   
	\item Ricardo Reis's model. \cite{reis2006inattentive}
	\item Xavier Gabaix's sparse matrix model. \cite{gabaix2014sparsity}
\end{itemize}

\item Epidemiologic view. \cite{carroll2003macroeconomic} Regardless of the microfoundations of the information rigidity, households infrequently get access to more rational-and-up-to-date expectations from professional forecasters with a poisson process. 


\item Strategic behaviors. Second order belief, i.e., what you believe of what others believe. \cite{angeletos2009incomplete}



\end{enumerate}

\section{Empirical Results}

\subsection{Data}

\begin{itemize}
	
		\item \textbf{New York Fed Survey of Consumer Expectation}
	\begin{itemize}
			\item Include not only perceived probabilities of binary event as in Michigan Survey does, but also elicit densitity forecasts. 
	\end{itemize}
	\item \textbf{Professional Forecasters}

\end{itemize}

A summary of the data information is as below. 

\begin{table}[]
			\caption{Information of Data}
	\begin{tabular}{lll}

		\hline 
		& SCE & SPF        \\
		\hline 
		Time period                                    & 2013-present                            & 2007-present             \\
		Frequency                                      & Monthly                                 & Quarterly                \\
		Sample Size                                    & 1,300                                   & 30-50                    \\
		Aggregate Var in Density                       & 1-yr  and 3-yr ahead inflation          & 1-yr CPI and PCE         \\
		Individual Var in Density                      & 1-yr earning growth                     & No                       \\
		Pannel Structure                               & stay up to 12 months                    & average stay for 5 years \\
		Demographic Info                        & Education, Income, Age, Location        & Industry    \\
		\hline 
	\end{tabular}
\end{table}


\subsection{Density Estimates}


\subsection{Test of Null Hypothesis of Rational Expectation}

\subsubsection{Replicating  \cite{fuhrer2018intrinsic}}

\subsection{Professional Forecasters as a Benchmark}

\subsubsection{Replicating \cite{coibion2012can}}

\subsubsection{Additional Evidence from Uncertainty}

\subsection{Evidence from Households}

\section{Conclusion}


\bibliographystyle{apalike}
\bibliography{TestingExpectationTheories}

\end{document}
