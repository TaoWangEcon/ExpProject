\documentclass[]{article}
\usepackage{amsmath}
\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage[a4paper,bindingoffset=0.2in,%
left=1in,right=1in,top=1.2in,bottom=1.2in,%
footskip=.25in]{geometry}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=blue,      
	urlcolor=blue,
	citecolor=blue
}
\usepackage{natbib}

%opening
\title{Rigidity of Expectation: Additional Evidence from Density Forecasts of Professionals and Households}
\author{Tao Wang}


\begin{document}
	
	\maketitle
	
	\begin{abstract}
		Surveys on density forecasts of macroeconomic variable that are not available until recent two decades provides one additional moment restriction, uncertainty, for testing and exploring the implications of various theories on expectation formation. This paper first documents the persistent dispersion in uncertainty about future inflation across economists and households. Second,  utilizing the panel data of individual uncertainty, I provide additional test results and estimates that are not consistent with the benchmark prediction of full-information rational expectation (FIRE). Finally, using externally identified shocks to inflation, I show the dynamic responses of forecasting moments to shocks are broadly consistent with theories of expectation rigidity and points to evidence for shock-dependent nature of the rigidity.  This sets the stage for estimating shock-specific rigidity using uncertainty as the next step of analysis.  
		
	\end{abstract}
	
	\newpage 
	
	\section{Introduction}
	
	
	Theories on how agents form expectations in ways deviating from rational expectation(RE) have proliferated over the past decade. This has been also engined by an increasingly welcoming recognition of the use of surveys by macroeconomists in testing theories empirically.  On one hand, various theories built upon different micro foundations produce some similar macro patterns. For instance, the notion of information rigidity, or expectation rigidity could be micro founded by many different theories, but mostly generate sluggish response to new information.  On the other hand, there are important and subtle differences in testable predictions from these theories for both individual forecasts and aggregate moments of the forecasts. 
	
	This paper extends the current literature in this front by deriving the testable predictions from various theories on uncertainty and empirically test them utilizing the previously ignored probabilistic forecast from both professional forecasters survey and household survey. Overall, the paper finds additional evidence from uncertainty consistent with the rigidity models. But in the same time, the degree of rigidity appears to be shock-specific and bears the difference to households and professional forecasters. 
	
	The contributions of this paper primarily rely upon the additional insights from the forecast uncertainty, that is only available if surveyees are asked to assign their perceived probabilities to a range of variables of the forecast. .\footnote{For an insightful survey on the importance of measuring subjective expectations using probabilistic surveys, see \citet{manski2004measuring}.} With density forecasts. the variance of individual forecast can be estimated as an indicator of the uncertainty. Across different vintages of the forecast, the revision in uncertainty is a direct measure of  information gain or the degree of forecasting efficiency. Besides, as in a typical signal-extraction model, the prediction that new information reduce conditional variance can be tested only using probability distributions.   
	
	\section{Theories of Expectation Formation}\label{theory}
	
	\subsection{Definition of moments}
	
	An agent $i$ is forming expectations about a stochastic variable $y^i_{t+h}$. The supscript $i$ can be dropped if it is an aggregate (i.e. inflation) variable instead of individual specific  (i.e. household income or house value). This paper focuses on forecasting of aggregate variables, in particular, inflation. So we can simply denote the variable as $y_{t+h}$. To put it another way, all agents are forecasting the same object. \footnote{Only in the context of forecasting aggregate variable, it is meaningful to study the average expectations and disagreements across agents.}
	
	Denote $ f_{i,t+h|t}$ as agent i's $h$-period-ahead density forecast. $ f_{i,t+h|t}$ is the conditional density of $y_{i,t+h}$ given the information set $I_{i,t}$ available at time $t$. 
	
	$$f_{i,t+h|t} \equiv f_{i,t}(y_{t+h}|I_{i,t})$$
	
	
	$I_{i,t}$ is the information set available for individual $i$ at time t. The information set can be  agent specific, thus it has subscript $i$.  The specific content contained in $I_t$ varies from different models of expectation. For instance, sticky expectation and rational inattention literature all assume that agents are not able to update new information instantaneously. So the information set may not contain the most recent realization of the variable of forecast $y_t$. \footnote{Given the same information set available to agents, different theories may also differ in the underlying models each agent use to form the conditional density of the variables by agent $i$. Examples of such include multi-prior or model uncertainty. \citet{xx}. }
	
	Accordingly, h-period ahead mean forecast at $t$, denoted as $ y_{i,t+h|t}$, is the conditional expectation of $y_{t+h}$ by the agent $i$. 
	
	$$y_{i,t+h|t} \equiv E_{i,t}(y_{t+h}) =\int f_{i, t+h|t} d y_{t+h}$$
	
	Similarly, individual forecasting variance $\sigma_{i,t+h|t}$, hereafter termed as individual uncertainty in this paper, is the conditional variance.
	
	$$\sigma^2_{i,t+h|t} \equiv Var_{i,t}( y_{t+h} )$$
	
	Individual forecast error $FE_{i,t+h|t}$ is the difference of ex post realized value of $y_{t+h}$ and individual forecast at time $t$. 
	
	$$FE_{i,t+h|t} = y_{i,t+h|t} - y_{t+h}$$
	
	The population analogues of individual mean forecast, uncertainty and forecast errors are simply the average of the individual moments taken across agents. Denote them as $\bar y_{t+h|t}$, $\bar \sigma^2_{t+h|t}$, and $\overline{FE}_{t+h|t}$, respectively. Hereafter, they are termed as population mean forecast, population uncertainty and population forecast error, respectively. In addition, disagreements is defined as the cross-sectional variance of mean forecasts of individual agents.  Denote it as $\overline{Var}_{t+h|t}(y_{i,t+h|t}) $. To simplify notation, let us directly call it $\overline{Disg}_{t+h|t}$.  \footnote{This is the same terminology used by \citet{xx}.}
	
	In summary, we have 3 individual moments and 4 population moments listed in below in Table \ref{MomSum}.
	
	\begin{table}[]
		\centering
		\caption{Definition and Notation of Moments}
		\label{MomSum}
		\begin{tabular}{ll}
			
			\hline 
			Individual Moments                                  & Population Moments                             \\
			\hline 
			Mean forecast: $y_{i,t+h|t}$                   & Average forecast: $\bar y_{t+h|t}$                   \\
			Forecast error: $FE_{i,t+h|t}$ & Average forecast error: $\overline{FE}_{t+h|t}$ \\
			Uncertainty: $\sigma^2_{i,t+h|t}$         & Average uncertainty:  $\bar \sigma^2_{i,t+h|t}$ \\
			& Disagreements:  $\overline{Disg}_{t+h|t}$       \\
			\hline 
		\end{tabular}
	\end{table}
	
	Finally, we assume the underlying true process of $y_{t}$ is $AR(1)$ with persistency parameter $0<\rho <1$ and i.i.d. shock $\omega_t$. 
	
	\begin{eqnarray}\label{AR_process}
		y_{t+1} = \rho y_t + \omega_t
	\end{eqnarray}
	
	$$\omega_t \sim N(0,\sigma^2_{\omega})$$
	
	\subsection{Benchmark of full-information rational expectation(FIRE)}
	
	In the FIRE benchmark,  it is assumed that all agents perfectly observe $y_t$ at time $t$ and understand the true process of $y$. Therefore, individual forecast is $\rho^h y_t $, which is shared by all agents. Therefore, it is also equal to average forecast. 
	
	Both individual and population forecast errors are simply the realized shocks between $t+1$ to $t+h$.  
	
	\begin{eqnarray}\label{NoPastInfFE}
		\overline{FE}^{*}_{i,t+h|t} = \sum^{h-1}_{s=1} \rho^s \omega_{t+h-s}
	\end{eqnarray}
	
	I use supscrit of $*$ to denote all the moments according to FIRE. It is easy to see that the forecast error is orthogonal to information available till time $t$. This provides the a well known null hypothesis of FIRE. \citet{xx}
	
	The second implication from FIRE here is that forecast errors of non-overlapping horizon forecasts are not correlated. For instance, forecast error at time $t$ and that at time $t+h$ or further are not serially correlated. This is not the case within $h$ periods as the realized shocks in overlapping periods enter both forecast errors. 
	
	\begin{eqnarray}\label{NoSerialCorrFE}
		Cov(\overline{FE}^{*}_{t+h|t}, \overline{FE}^{*}_{t+s+h|t+s}) = 0 \quad \forall s \geq h
	\end{eqnarray}
	
	FIRE also has predictions about  population disagreements. \footnote{For instance, \citet{mankiw2003disagreement} documents substantial time-varying disagreements about future inflation using consumers and professional forecasters' survey. } As agents perfect update the same information, there is no disagreements at any point of the time. 
	
	$$\overline{Disg}^{*}_{t+h|t}=0 \quad \forall t$$
	
	A corollary is that disagreements do not respond to realized shocks any any point of the time.  \footnote{Empirical tests of this kind include \citet{xx}.\citet{xx} etc. }
	
	In addition to forecast error and disagreements, according to FIRE all individual shares the same degree of uncertainty. The uncertainty simply comes from uncertainty about future unrealized shocks between $t$ and $t+h$. To put it another way, according to FIRE, there is neither disagreements about mean, nor disagreements about the uncertainty \footnote{This is the same to \citet{}'s terminology.} 
	
	$$\bar \sigma^{*2}_{t+h|t} = \sum^{h}_{s=1}\rho^{2s} \sigma^2_{\omega}$$
	
	The time series behavior of uncertainty according to FIRE is less obvious. Weather it is time-variant depends on if the variance of the shocks $\omega_t$ is time varying. Although in our baseline case we make such an assumption, in general it may not be true. \footnote{\citet{xx} on time-varying volatility.}
	
	In the same time, the serial correlation of uncertainty across different horizons of forecasting does follow testable pattern according to FIRE. In particular, consistent with our current notation, let us denote the forecast of $y_{t+h}$ over horizon of $h-k$ as $y_{t+h|t+k} \quad \forall k =0,1...h$. 
	
	\begin{eqnarray}\label{VarREPop}
		\bar \sigma^{*2}_{t+h|t+k} = \sum^{h-k}_{s=1}\rho^{2s} \sigma^2_{\omega}
	\end{eqnarray}
	
	As the forecasting horizon decreases relative to a given future point of time, there is a pure efficiency gain or reduction in uncertainty as more and more shocks have realized. So the uncertainty should drop unambiguously. 
	
	An equivalent interpretation to this is through the perspective of revision. Defining the forecast revision as the difference of different vintages of forecasts fixing the terminate date, the revision in uncertainty should be always negative and the drop should be exactly equal to discounted variance of the realized shocks. \footnote{Compared to other null hypotheses discussed above, this is a weaker test. It is true that rational forecasting implies reduction in uncertainty with shorter horizon. But there is no direct test if the drop in uncertainty is efficient enough so as to be consistent with FIRE. }
	
	$$\bar \sigma^{*2}_{t+h|t+1} - \bar \sigma^{*2}_{t+h|t} = - \rho^{2h}\sigma^2_\omega$$
	
	
	\subsection{Sticky Expectation (SE)}
	
	The theory of sticky expectation (\citet{xx}, \citet{xx} ), regardless of its different micro-foundations by various authors, builds upon the assumption that agents do not update information instantaneously as they do in FIRE. One of the most tractable models assume there is a homogenous Poisson rate $\lambda$ of updating among the population. Specifically, at any point of time $t$, each agent learns about the up-to-date realization of $y_t$ with probability of $\lambda$; otherwise, it forms the expectation based on the most recent up-to-date realization of $y_{t-\tau}$, where $\tau$ is the time experienced since previous update. 
	
	
	
	
	\subsubsection{Individual moments} 
	
	Denote the mean forecast of a non-updater since $t-\tau$ as $y_{i,t+h|t-\tau}$ since her forecast conditions upon the information up till $t-\tau$.
	
	$$y_{i,t+h|t-\tau} = \rho^{h+\tau} y_{t-\tau}$$
	
	Now her information set is not up to date, the uncertainty to a non-updater is higher than an updater and it increases with the duration of non-updating $\tau$. 
	
	\begin{eqnarray}\label{VarSEInd}
		\sigma^2_{i,t|t-\tau}= \sum^{h+\tau}_{s=1}\rho^{2s} \sigma^2_{\omega}
	\end{eqnarray}	
	
	In FIRE, updating at each period $t$ resolves only the uncertainty about the shocks realizing in $t$. In constrast, in SE each updating resolves the uncertainty about all the realized shocks since last update. Fixing the terminate date, i.e. forecasting  $y_{t+1}$ at time $t$ relative to forecasting $y_{t+1}$ at $t-\tau$, the revision in uncertainty is 
	
	$$\sigma^2_{i,t+1|t} - \sigma^2_{i,t+1|t-\tau} = \rho^{2} \sigma^2_{\omega} - \sum^{\tau+1}_{s=1}\rho^{2s} \sigma^2_{\omega} = -\sum^{\tau+1}_{s=2} \rho^{2s}\sigma^2_{\omega}$$
	
	FIRE assumes  $\tau=1$ for all the agents and all the time, namely all agents' last update takes place in previous period. So setting $\tau =1$ in above equation gives the reduction in uncertainty in FIRE. One can easily see that the reduction in uncertainty is greater in SE for any $\tau>1$ than FIRE.
	
	In summary, the key difference between FIRE and SE with respect to behavior of uncertainty is that the later does not reduce uncertainty  as efficiently as in the former primarily because of the rigidity incorporating new information.  One qualitative pattern from this difference is that any evidence of ambiguous pattern  or non-negative revision in uncertainty is inconsistent with FIRE. \footnote{Because of this, the difference in average responses in variance to new information may speak to potential heterogeneity in information rigidity. According to the theory above, higher information rigidity implies high volatility of variance responses.  }
	
	
	
	\subsubsection{Population moments} 
	
	It is important to note that the rigidity in updating according to SE cannot be systematically observable in the individual level, both in terms of forecasts errors and uncertainty. This is because the behaviors of each individual forecast specifically depends on if the she updates or not in that period. 
	
	Relying upon the Law of Large Numbers, we can derive testable predictions about population moments that allow us perform tests of sticky expectation and recover rigidity parameter $\lambda$. \footnote{\citet{carroll2003macroeconomic} is one notable example of this.} 
	
	
	One well known prediction from SE literature is that the average forecast is a weighted average of update-to-date rational expectation and lagged average expectation as reproduced below. \footnote{See \citet{coibion2012can} or appendix of this paper for detailed steps.} It can be also expressed as a weighted average to all the past realizations of $y$. Setting $\lambda=1$, then the SE collapses to FIRE and the average forecast is equal to $y$'s long-run mean of zero.
	
	\begin{eqnarray}
		\begin{aligned}
			\bar y_{t+h|t} & = \lambda \underbrace{y^*_{t+h|t}}_{\textrm{rational expectation at t}} + (1-\lambda) \underbrace{\bar y_{t+h|t-1}}_{\textrm{average forecast at } t-1} \\
			& = \lambda \sum^{\infty}_{s=0} (1-\lambda)^s y^*_{t+h|t-s} \\
			& = \lambda \sum^{\infty}_{s=0} (1-\lambda)^s \rho^{s+h}y_{t-s}
		\end{aligned}
	\end{eqnarray}
	
	It is also easy to show that the average forecast errors are serially correlated. Setting $\lambda=1$, then the SE collapses to FIRE, in which there is no serial correlation between forecast errors and it fully respond to newly realized shocks at time $t$.  \footnote{Need to check if is revision or change from}
	
	\begin{eqnarray}
		\begin{aligned}
			\overline{FE}_{t+h|t}  = (1-\lambda) \overline {FE}_{t+h-1|t-1} + \lambda \rho^h \omega_t 
		\end{aligned}
	\end{eqnarray}
	
	
	\citet{coibion2012can} also derives predictions about the disagreements in rigidity models. Unlike zero disagreements in FIRE, SE is characterized by non-zero dispersion in forecasting because of different lags in updating across populations. \footnote{need to check if correct also. Need to derive change in disagreements.} 
	
	\begin{eqnarray}
		\begin{aligned}
			\overline{Disg}_{t+h|t} & = \lambda \sum^{\infty}_{\tau=0} (1-\lambda)^{\tau} (y_{t+h|t-\tau} - \bar y_{t+h|t }))^2  
		\end{aligned}
	\end{eqnarray}
	
	From time $t$ to $t+1$, the change in disagreements comes from two sources. One is newly realized shock at time $t+1$. The other component is from people who did not update at time $t$ and update at time $t+1$.  
	
	In SE, disagreements rise after realization of the shock and gradually returns to its steady state level. In the same time, it does not depend upon the particular realization of the shock. \citet{coibion2012can} derive the impulse response of dispersion at time $t+j$ to a shock that realized at $t$. 
	
	\begin{eqnarray}
		\rho^{2(h+j)} (1-\lambda^{j+1})\lambda^{j+1} \omega^2_t
	\end{eqnarray}
	
	Finally, SE predicts an sluggish inefficiency in revision in uncertainty. Average uncertainty at any point of time is now a weighted average of uncertainty to agents whose last updates have taken place in different periods of past.  
	
	\begin{eqnarray}\label{VarSEPop}
		\begin{aligned}
			\bar \sigma^2_{t+h|t} & = \sum^{+\infty}_{\tau =0} \underbrace{\lambda (1-\lambda)^\tau}_{\text{fraction who non-updater until }t-\tau} \underbrace{\sigma^2_{t+h|t-\tau}}_{\text{ uncertainty of most recent update at }t-\tau} \\
			& = \sum^{+\infty}_{\tau =0} \lambda (1-\lambda)^\tau \sum^{h+\tau}_{s=0}\rho^{2s} \sigma^2_{\omega}
		\end{aligned}
	\end{eqnarray}
	
	Since not all agents incorporate the recent realized shocks, the revision in average uncertainty exhibits serial correlation described as below in a similar spirt of forecast errors. It is equal to a weighted average of the resolution of uncertainty from the most recent shocks and its lagged counterpart. \footnote{Make sure you have clarify the difference between revision and change.}
	
	
	\begin{eqnarray}\label{VarSERv}
		\begin{aligned}
			\bar \sigma^2_{t+h|t+1} - \bar \sigma^2_{t+h|t} = (1-\lambda)(
			\bar \sigma^2_{t+h|t} - \bar \sigma^2_{t+h|t-1}) -\lambda \rho^{2h} \sigma^2 
		\end{aligned}
	\end{eqnarray}
	
	In particular, the second component is the information gain from most recent realization of the shock underweighted by $\lambda<1$. The first component is the inefficiency sourced from stickiness of updating. The higher rigidity (lower $\lambda$), the smaller the efficiency gain or uncertainty reduction from one vintage of forecast to the next compared to its FIRE correspondents. 
	
	\subsubsection{Summary of predictions of SE}
	
	\begin{itemize}
		\item Individual uncertainty need not unambiguously drop with shorter horizon. 
		\item Population mean forecast partially responds to shocks and with lags. 
		\item Forecast errors are serially correlated. 
		\item Population disagreements rise in response to new shocks and return to steady state level gradually. 
		\item Population average uncertainty revision is serially correlated and underreacts to volatility of the shocks.
		
	\end{itemize}
	
	\subsection{Noisy information(NI)}
	
	A class of noisy information models (\citet{},\citet{}) describes the expectation formation as a process of extracting or filtering true variable $y_t$ from a sequence of realized signals. The starting assumption is that agent cannot observe the true variable perfectly. Unlike information rigidity model, it is assumed that agents keep track of the realizations of the signals instantaneously all the time. 
	
	We assume agent $i$ observe two signals $s^{pb}$ and $s^{pr}_i$, with $s^{pb}$ being public signal common to all agents, and $s^{pr}_i$ private signals being individual specific with subscript $i$. The generating process of two signals are assumed to be the following.
	
	\begin{eqnarray}
		\begin{aligned}
			s^{pb}_t = y_t + \epsilon_t, \quad \epsilon_t \sim N(0,\sigma^2_\epsilon)\\ 
			s^{pr}_{i,t} = y_t + \xi_{i,t} \quad \xi_{i,t} \sim N(0,\sigma^2_\epsilon)
		\end{aligned}
	\end{eqnarray}
	
	Stacking the two signals into one vector $s_{i,t} = [s^{pb}_t,s^{pr}_{i,t}]'$ and $v_{i,t}= [\epsilon_t,\xi_{i,t}]'$, the equations above can be rewritten as 
	
	\begin{eqnarray}
		\begin{aligned}
			s_{i,t} = H y_{t} + v_{i,t} \\
			\text{where } & H=[1,1]' \quad \\
		\end{aligned}
	\end{eqnarray}
	
	
	\subsubsection{Individual moments }
	
	Now any agent trying to forecast future $y$ has to form her expectation of the contemporaneous $y$. Denote it as  $y_{i,t|t}$, which needs to be inferred from the signals to agent $i$. The agent's best h-period ahead forecast is simply iterated $h$ periods forward based on the AR(1) process and it is equal to $\rho^h y_{i,t|t}$. This is the same as FIRE.
	
	What is different from FIRE is that the agent makes her best guess of $y_t$ using Kalman filtering at time $t$. Specifically, mean forecast of individual $i$ is the posterior mean of based on her prior and realized signals $s_i$. 
	
	
	\begin{eqnarray}
		\begin{aligned}
			y_{i,t|t}  
			& =  \underbrace{y_{i,t|t-1}}_{\text{prior}} + P \underbrace {(s_{i,t|t}-s_{i,t|t-1})}_{\text{innovations to signals}} \\
			& = (1-PH) y_{t|t-1} + Ps_{i,t} \\
			& = (1-PH) y_{t|t-1} + PH y_{i,t} + P v_{i,t} 
		\end{aligned}
	\end{eqnarray}
	
	where the Kalman gain  
	
	
	\begin{eqnarray}
		\begin{aligned}
			P = [P_\epsilon,P_\xi]= \Sigma^y_{i,t|t-1} H(H'\Sigma^y_{i,t|t-1} H + \Sigma^v)^{-1} 
		\end{aligned}
	\end{eqnarray}
	
	and $\Sigma^y_{i,t|t-1}$  is the variance of  $y_t$ based on prior belief.
	
	\begin{eqnarray}
		\begin{aligned}
			\Sigma^v =  \left[ \begin{matrix} 
				\sigma^2_{\epsilon} &  0 \\ 
				0 & \sigma^2_\xi \end{matrix}\right] 
		\end{aligned}
	\end{eqnarray}
	
	Individual forecast partially responds to new signals, i.e. $P<1$. $P=1$ is a special case when both signals are perfect thus $\Sigma^v = 0$, then the formula collapses to FIRE. 
	
	Now, the parameter that governs rigidity is $1-PH$. It is a function of prior uncertainty about $y$ and noisiness of the signals. It is time variant as the variance is updated by the agent each period.  
	
	There are a few important distinctions between NI and SE. 
	
	First, the serial correlation of forecast error exists at both individual and population level, while it is only observable in population moments according to SE. 
	
	To see this, the change in individual forecast from $t-1$ to $t$ is \footnote{need to check.}
	
	\begin{eqnarray}
		\begin{aligned}
			\Delta y_{i,t+h|t} & = \underbrace{\rho^h (1-PH)\Delta y_{i,t+h|t-1}}_{\text{Lagged response}} + \underbrace{\rho^hPH \Delta y_{i,t|t} + \rho^h P\Delta v_{i,t}}_{\text{Shocks to signals}}\\
		\end{aligned}
	\end{eqnarray}
	
	The serial correlation is $\rho^h(1-PH)$, it does not only depend on $PH$, but also the forecast horizon $h$. As $\rho<1$, the rigidity declines with longer horizon. In this regard, the rigidity implied by NI and SE are different because the form is fixed and the later is horizon dependent.  
	
	Second, the expectation adjusts in each period as long as there is new information. In sticky expectation, however, the expectation adjusts only when the agent updates. 
	
	
	The posterior variance at time $t$ is a linear function of prior variance and variance of signals. 
	
	\begin{eqnarray}\label{VarNIRv}
		\begin{aligned}
			\Sigma^y_{i,t|t} = \Sigma^y_{i,t|t-1} - \Sigma^y_{i,t|t-1} H'(H \Sigma^y_{i,t-1} H' +\Sigma^v) H \Sigma^y_{i,t|t-1} 
		\end{aligned}
	\end{eqnarray}
	
	
	As in FIRE and SE, uncertainty itself does not depend upon the realization of the shocks or signals. The revision in uncertainty from time $t-1$ to $t$ fixing the terminate of the forecast date is negative  unambiguously. To see this 
	
	\begin{eqnarray}
		\Sigma^y_{i,t|t} - \Sigma^y_{i,t|t-1} = - \Sigma^y_{i,t|t-1} H'(H \Sigma^y_{i,t-1} H' +\Sigma^v) H \Sigma^y_{i,t|t-1} <0
	\end{eqnarray}
	
	But the efficiency gain in reduction of uncertainty depends upon the noisiness of the signals. As long as the signal is not perfect, forecast in NI is neither as efficient as FIRE. 
	
	These two properties carry through to the h-period ahead forecast as well. As the forecast variance is the following 
	
	\begin{eqnarray}\label{VarNIEq}
		\Sigma_{i,t+h|t} = \rho^{2h} \underbrace{\Sigma_{i,t}}_{\Sigma_{i,t|t}} + \sum^{h}_{s=0}\rho^{2s} \sigma^2_{\omega}
	\end{eqnarray}
	
	
	\begin{eqnarray}\label{VarNIIndPop}
		\Delta \Sigma_{i,t+h|t} = \rho^{2h}\Delta  \Sigma_{i,t|t}  - \rho^{2h} \sigma^2_{\omega}
	\end{eqnarray}
	
	From $t$ to $t+1$, when $h\geq 1$, the decline in variance come from two sources. The first source is the pure gain from the new signals, i.e. $\Delta \Sigma^y_{i,t|t}$. It is scaled by the factor $\rho^{2h}$. The second source is present in full information rational expectation model: as time goes from $t-1$ to $t$, there is a reduction of uncertainty about $\omega_t$.
	
	Figure \ref{IllustrateNI} illustrates both the signal extraction problem at each period of $t+k$ and how it is used to predict the prediction of $y_{t+h}$. 
	
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=13cm]{figures/ni_illustration.png}  
		\caption{Nowcasting and Forecasting in Noisy Information}
		\label{IllustrateNI}
	\end{figure}
	
	
	\subsubsection{Population moments}
	
	\begin{eqnarray}
		\begin{aligned}
			\bar y_{t+h|t} & = \rho^h [(1-PH) \underbrace{\bar  y_{t+h|t-1}}_{\text{Average prior}} + P \underbrace{\bar s_{t}}_{\text{Average Signals}}] \\
			& = (1-PH) \bar y_{t+h|t-1}+ P [\epsilon_t, 0]' \\
			& = (1-PH) \bar y_{t+h|t-1} + P \epsilon_t
		\end{aligned}
	\end{eqnarray}
	
	One of the major implications from NI models is that both individual forecast and uncertainty behaves the same pattern as population forecasts. 
	
	In particular, the same as individual forecast error, average forecast errors have serial correlation with the same auto regression parameter $\rho^h(1-PH)$. 
	
	As to the uncertainty, as it does not depend on realized signals and the precision is the same across all agents, average variance $\bar \Sigma_{t+h|t}$ is equal to the variance of each individual. 
	
	Also, same as the individual variance, the variance unambiguously drop in each vintage of revision. But since the signal is noisy, agents partially react to the news and uncertainty does not drop as efficiently as FIRE. 
	
	\begin{eqnarray}
		\bar \Sigma^2_{t+h|t} -  \bar \Sigma^2_{t+h|t-1}< 0 
	\end{eqnarray}
	
	NI also predicts non-zero disagreements in the presence of private signals. The behavior of disagreements across agents come from the difference in realized private signals. Specifically, it is equal to the following. 
	
	\begin{eqnarray}
		\begin{aligned}
			\overline {Disg}_{t+h|t} = \rho^{2h} P^2_\xi \sigma^2_\xi  
		\end{aligned}
	\end{eqnarray}
	
	First, the disagreements increase with the forecast horizon.  Second, the disagreements depends on noisiness private signals, but not on that of public signals and the variance of the true variable $y$. Third, similar to SE, the disagreements also increase with the rigidity parameter $P$ in this model.
	
	The disagreements increase as time goes from $t-1$ to $t$. Also, as the time approaches $t+h$, the disagreements increase. This seems counterintuitive. But the reason is that here the disagreements always exist simply because agents receive private signals, this disagreements is actually amplified as time goes forward. 
	
	
	\subsubsection{Summary of predictions from noisy information}
	
	$\bullet$  Individual expectation adjusts in each period, but only partially adjusts to new information. \\
	$\bullet$ Unlike sticky expectation, sluggishness in adjustment or serial correlation of adjustment exists in individual level. The correlation parameter decreases with forecast horizon, which is not the case in sticky expectation.\\
	$\bullet$  Individual variance unambiguously drops each period as one approaches the period of realization. In sticky expectation, it increases regardless of updating or not. \\ 
	$\bullet$  Population average forecast partially adjusts to news and has serial correlation as the individual level. \\
	$\bullet$  Population disagreements rise in each period as time approaches the period of realization. Disagreements will never be zero. \\
	$\bullet$  Average variance declines unambiguously each period. 
	
	\subsection{Comparing FIRE, SE and NI}
	
	Figure \ref{ir_pop} plots the impulse responses of population moments of forecasts according to different theories. As we focus on the dynamics of revision as one approaches the terminate date, i.e. forecast of $y_{t+h}$ at $t$, $t+1$, $t+2$ till $t+h$ instead of forecasts with fixed horizon, i.e. $y_{t+h}$,$y_{t+h+1}$. 
	
	This is the most intuitively seen in the dynamics of uncertainty. In particular, as one approach the realization $t+h$, uncertainty necessarily drop for FIRE and attains zero at the last period.  
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=16cm]{figures/ir_popseni.png} 
		\caption{Impulse responses of moments to a shock to inflation}
		\label{ir_pop}
	\end{figure}
	
	One of the common predictions of SE and NI is there is information rigidity or stickiness of expectations.  But both theories have subtle difference in implied rigidity. I illustrate this in Figure \ref{rigidity}. One notable difference is that SE's rigidity is exogenously fixed. NI's rigidity is endogenously determined by the noisiness of the signals and it is time varying. 
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=13cm]{figures/rigidity.png} 
		\caption{Rigidity from Two Models}
		\label{rigidity}
	\end{figure}
	
	
	\subsection{Discussion of other theories}
	
	\begin{enumerate}
		\item Rational inattention. 
		\begin{itemize}
			\item Chris Sim's model.\citet{sims2003implications} Information serves the role of uncertainty reduction measured by relative entropy. Agents optimally trade off the fixed cost of being attentative versus the gain from uncertainty gain.   
			\item Ricardo Reis's model. \citet{reis2006inattentive}
			\item Xavier Gabaix's sparse matrix model. \citet{gabaix2014sparsity}
		\end{itemize}
		
		\item Epidemiological view. \citet{carroll2003macroeconomic} Regardless of the micro-foundations of the information rigidity, households infrequently get access to more rational-and-up-to-date expectations from professional forecasters with a poisson process. 
		
		
		\item Strategic behaviors. Second order belief, i.e., what you believe of what others believe. \citet{angeletos2009incomplete}
		
		
		
	\end{enumerate}
	
	\section{Empirical Results}\label{empirical}
	
	\subsection{Data}
	
	
	Professional Forecasters(SPF) and New York Fed Survey of Consumer Expectation(SCE). 
	
	The structure of SPF allows us to directly test efficiency in revision as for the surveyees are asked to provide both current year forecast and 1-year-ahead inflation forecast each quarter. 
	
	SCE data, although each individual is surveyed for 12 months in a row, is only asked to forecast 1-year-ahead inflation. This is especially so in the density forecast. So we can only perform a weak test. 
	
	We follow \citet{engelberg2009comparing} to estimates the density distribution of each individual surveyee for SPF. New York Fed has followed the same procedures for SCE and directly provided their estimate of uncertainty. Therefore, I directly use them. 
	
	For SPF, I drop the outliers of mean forecast and uncertainty estimates at both top and bottom one percentiles as these are typically abnormals that are due to measurement errors or other reasons.   For SCE, I drop top and bottom 5 percentile of mean forecasts and uncertainty as households mean forecast re inclined to give extreme values. \footnote{(For mean forecasts and uncertainty, respectively, this means dropping 6528 and 5096 observations, out of 68887 observations in total.}
	
	
	A summary of the data information is as below. 
	
	\begin{table}[ht]
		\caption{Information of Data}
		\label{DataInfo}
		\begin{tabular}{lll} 
			
			\hline 
			& SCE & SPF        \\
			\hline 
			Time period                                    & 2013-present                            & 2007-present             \\
			Frequency                                      & Monthly                                 & Quarterly                \\
			Sample Size                                    & 1,300                                   & 30-50                    \\
			Aggregate Var in Density                       & 1-yr  and 3-yr ahead inflation          & 1-yr CPI and PCE         \\
			Individual Var in Density                      & 1-yr earning growth                     & No                       \\
			Pannel Structure                               & stay up to 12 months                    & average stay for 5 years \\
			Demographic Info                        & Education, Income, Age, Location        & Industry    \\
			\hline 
		\end{tabular}
	\end{table}
	
	Throughout the paper, I use two measures of Inflation, headline CPI inflation and PCE inflation. The forecasts-based measures are computed and used correspondingly.  
	
	\subsection{Stylized facts}
	
	
	Although the sheer magnitudes of the differences between professionals' moments and those of households are so big that a direct comparison of the two seems redundant, their respective within-agent-type correlation serves a ready checking device of some statistical consistency. Figure \ref{UnceratitnyOtherMoments} plots the population uncertainty against realized inflation,  forecast errors and disagreements in the first, second and third rows, respectively. 
	
	It is widely documented in literature \cite{xxx, xxx} and resonated by anecdotal narrative that high inflation is typically associated with high inflation uncertainty. However, the observable correlation of realized inflation and the directly estimated average uncertainty from both  forecasters and households are, if any, negative during the period between 2007-2019. In particular, the correlation coefficients are -0.1, -0.05 and -0.24 for SPF's  CPI forecast, SPF's PCE forecast and SCE's CPI expectation. This may suggest that during a period of persistently low inflation, the conventional positive redux of inflation and uncertainty is not a good description of the relation of the two. 
	
	The middle row of Figure \ref{UnceratitnyOtherMoments} looks into the relationship between forecast error and uncertainty. Although according to our benchmark framework in \ref{theory}, there is no mathematical correlation between the forecast errors and uncertainty as the former depends on the realized shocks and the later depends on the volatility of the shock, it is worth checking if in the data a greater ex ante uncertainty implies bigger ex post forecast errors. The correlation coefficient of the two are 0.13, 0.06 and 040 for SPF CPI forecasts, SPF PCE forecasts and SCE households forecasts, respectively. Compared to professional forecasts, households forecasts exhibit such a positive correlation.  
	
	The last row in of Figure \ref{UnceratitnyOtherMoments} explores the relationship between disagreements and uncertainty. Many empirical literature in macroeconomics use disagreements and uncertainty as if they are similar concepts. Partly this confusion in practice is due to difficulty of finding the appropriate measure of this in the first place. But as we have presented in \ref{theory}, the two are distinct concepts. The empirical pattern of the two,  as shown in the plots, also confirms that the two are different objects. The correlation coefficients of the two turn out to be negative, -0.29 and -0.46 for SPF forecasts. In stark contrast, households seem to bear a strong correlation of 0.62 between the two moments.  
	
	Overall, professional forecasters' moments exhibit patterns more consistency from a statistical point of view.  In contrast, the positive correlation across households' ex ante uncertainty, ex post forecast errors, and cross-section disagreements cannot be easily reconciled by the framework we set up in Section \ref{theory}. 
	
	Persistent disagreements in expectations has been used as an important stylized evidence against the null of identical expectation assumption embedded in FIRE, for instance, \citet{mankiw2003disagreement}. A similar fact checking can be done with respect to individual uncertainty. FIRE predicts individual share equal degree of uncertainty as  seen in Equation \ref{VarREInd}. In contrast, SE predicts that uncertainty of individuals differ in that agents are not equally updated at a point of the time (Equation \ref{VarSEInd}). NI allows for possibility of homogeneity in uncertainty only under stringent condition of the equal precision of signals and the same prior of uncertainty (Equation \ref{VarNIEq}). Therefore, presence of dispersion of uncertainty across agents can be read against FIRE.  
	
	Figure \ref{IQR_Unceratitny} plots the median inflation expectation along its 25/75 percentiles in the left and its counterpart in uncertainty in the right column.  Not only there is long-lasting dispersion in individual forecasts, i.e. disagreements, but also notable heterogeneity in uncertainty across agents.  And not surprisingly, the dispersion of both forecasts and uncertainty of households are both of a much greater magnitude than that of the professionals. The 25/75 inter-quantile-range of households point forecasts is 4-5 percentage points compared to 1 percentage point of professionals. And the IQR of uncertainty of households are around 150-200 times(12-14 times for standard deviation) as that of professional forecasters.  
	
	Beside, there are cross-agent-type difference and similarity in terms of distribution of uncertainty. Households' uncertainty are more skewed toward to the right (higher uncertainty), meaning there is a wide dispersion in the high values of uncertainty. This can be also seen in Figure \ref{Unceratitny_Histogram}, where I plot the kernel density estimated distribution of uncertainty by year on. What is common for both types of agents is that the dispersion in uncertainty is persistent over time and do not show much time-variation.  
	
	Another pattern worth discussing in Figure \ref{IQR_Unceratitny} is that there is a notable rise in the dispersion of professional forecasts in the recent 2-3 years, primarily driven by an increase of upper side of the forecast (i.e. 75 percentile forecast increases from 1\% to 2\%). \footnote{This should be interpreted with caution since the disagreements of SPF forecasts shown in bottom row of Figure \ref{UnceratitnyOtherMoments} actually exhibits a gradual decline. } This is consistent with the observation in top left two figures Figure \ref{Unceratitny_Histogram} that the distribution of inflation forecasts in recent years have become flatten.
	
	FIRE also predicts an unambiguous reduction in uncertainty as one approaches to the date of realization, where the drop is exactly equal to the volatility of the realized shocks. Although quantitatively it is hard to check this, one can look if the distribution of the uncertainty revision concentrate in the negative range. Figure \ref{RevisionHist} plots the average revision in mean forecasts and uncertainty from 1-year-ahead forecast in year $t-1$ to the current-year nowcast in year $t$. The more negative range in which the revision lies, the more ``rational'' of the forecast. Looking from the histograms, uncertainty revision shows left-skewness relative to zero. This implies on average,  more forecasters feel more certain for her nowcast relative to her forecast made one year before.  Unfortunately, since SCE does not provide the data structure for this purpose, we cannot make a comparison between two types of agents. A formal test of revision equal to zero or being negative will be carried out in the Section \ref{NullTest}. 
	
	
	\begin{figure}[ht]
		\centering
		\smallskip
		\includegraphics[width=4.5cm]{figures/Inf1yf_CPIAU_varSPFCPIQ.png}
		\includegraphics[width=4.5cm]{figures/Inf1yf_PCE_varSPFPCEQ.png}
		\includegraphics[width=4.5cm]{figures/Inf1yf_CPIAU_varSCEM.png}\\
		\smallskip
		\includegraphics[width=4.5cm]{figures/SPFCPI_FE_varSPFCPIQ.png}
		\includegraphics[width=4.5cm]{figures/SPFPCE_FE_varSPFPCEQ.png}
		\includegraphics[width=4.5cm]{figures/SCE_FE_varSCEM.png}\\
		\smallskip	
		\includegraphics[width=4.5cm]{figures/CPI_disg_varSPFCPIQ.png}
		\includegraphics[width=4.5cm]{figures/PCE_disg_varSPFPCEQ.png}
		\includegraphics[width=4.5cm]{figures/Q9_disg_varSCEM.png}\\
		\caption{Unceratinty and Other Moments}
		\label{UnceratitnyOtherMoments}
	\end{figure}
	
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=7cm]{figures/IQRmeanCPIQ.png} 
		\includegraphics[width=7cm]{figures/IQRvarCPIQ.png} \\
		\smallskip
		\includegraphics[width=7cm]{figures/IQRmeanPCEQ.png}
		\includegraphics[width=7cm]{figures/IQRvarPCEQ.png}\\
		\smallskip
		\includegraphics[width=7cm]{figures/IQRmeanSCEM.png}
		\includegraphics[width=7cm]{figures/IQRvarSCEM.png}\\
		\caption{Dispersion in Mean Forecast and Unceratinty }
		\label{IQR_Unceratitny}
	\end{figure}
	
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=7cm]{figures/PRCCPIMean1_hist.png} 
		\includegraphics[width=7cm]{figures/PRCCPIVar1_hist.png}  \\
		\smallskip
		\includegraphics[width=7cm]{figures/PRCPCEMean1_hist.png} 
		\includegraphics[width=7cm]{figures/PRCPCEVar1_hist.png}  \\
		\smallskip
		\includegraphics[width=7cm]{figures/SCEmean_hist.png} 
		\includegraphics[width=7cm]{figures/SCEvar_hist.png}  \\
		\caption{Distribution of Mean Forecast and Uncertainty }
		\label{Unceratitny_Histogram}
	\end{figure}
	
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=7cm]{figures/PRCCPIMean01_rv_true_hist.png} 
		\includegraphics[width=7cm]{figures/PRCCPIVar01_rv_true_hist.png}  \\
		\smallskip
		\includegraphics[width=7cm]{figures/PRCPCEMean01_rv_true_hist.png} 
		\includegraphics[width=7cm]{figures/PRCPCEVar01_rv_true_hist.png}  \\
		\caption{Distribution of Revision in Forecasts and Uncertainty}
		\label{RevisionHist}
	\end{figure}
	
	
	\subsection{Test of null hypothesis of rational expectation}\label{NullTest}
	
	This section first reproduces a number of statistical tests of FIRE used seen existing literature in Table \ref{NullTestTable}, primarily following \citet{mankiw2003disagreement},  and then extends the tests relying on uncertainty in Table \ref{RevEfficency} and \ref{WeakRevEfficiency}, in the spirit of forecasting efficiency by \citet{nordhaus1987forecasting}. It is an extension of what \citet{fuhrer2018intrinsic} does to mean forecast to uncertainty.  
	
	The first set of tests, hereafter, referred as FE-based tests, utilize the moment restrictions on forecast errors. In plain words, the null hypothesis of the three tests are the following. First, since the forecasts are on average unbiased according to FIRE, forecast errors across agents should converge to zero in large sample. Second, forecast errors of non-overlapping forecasting horizon are not serially correlated (Equation \ref{NoSerialCorrFE} ).  Third, forecast errors cannot be predicted by any information available at the time of forecast, including the mean forecast itself and other variable that is in the agent's information content. This follows from Equation \ref{NoPastInfFE}. In addition, I include what is called weak version of the FE-based test which explores the serial correlation of forecast errors in overlapping periods,  i.e. 1-year-ahead forecasts within one year. The forecast errors are correlated to the extent of the realized shocks in the overlapping periods. So the positive serial correlation does not direct violate FIRE. For this reason, looking into the correlation of overlapping forecast errors still contain the useful information about the size of the realized shocks. 
	
	FE-based tests results are presented in Table \ref{NullTestTable}. Individual level data are used thanks to the panel structure of both surveys. Since test 2 and 3 requires individual forecasts in vintages that are more than one year apart while SCE only surveys each household for 12 months, the two tests are done for only SPF forecasts of CPI and PCE. Also,the regressions are adjusted accordingly depending on the quarterly and monthly frequency of SPF and SCE. Since these regressions are based on 1-year inflations in overlapping periods, white standard error is computed for hypothesis testing. 
	
	First,  all three forecast series easily reject the unbiasedness test in the significance level of $1\%$. There is upward bias across professional forecasters and households \footnote{\citet{coibion2018firms} finds the same upward bias for firms' managers.}, while unsurprisingly, the bias is almost 20 times of that for professional forecasters(2.2 versus 0.12) for headline CPI. 
	
	Second, the point forecast one year ago predicts the forecast errors for professionals in the significance level of 1\%. For headline CPI inflation, for instance, one percentage point inflation forecast corresponds to 0.3 percentage points of the forecast errors one year later. Thus test 2 in Table \ref{NullTestTable} easily rejects the second hypothesis test of FIRE that past information does not predict future forecast errors. 
	
	Third, forecast errors can be predicted by forecast errors one year ago with a significant coefficient of around $0.08$ for headline CPI and $0.05$ for PCE, as seen in test 3 of Table \ref{NullTestTable}. Errors of non-overlapping forecasting periods are correlated, against the null of FIRE. 
	
	Lastly, test 4 in Table \ref{NullTestTable} presents higher serial correlation of forecast errros produced within a year. For SPF forecasts, the serial correlation does not exist beyond 1 quarter, implying relative efficiency of forecasts. For the households, the forecast errors are more persistent over the entire year in that current forecast errors are correlated with all past forecast errors over the past three quarters.  Again, although the persistency of 1-year forecast errors within one year do not directly violate FIRE, the fact that households' forecast errors being more persistent than professionals provide useful clues about the relative rigidity of the two types of agents. 
	
	\begin{table}[ht]
		\caption{Tests of Rationality and Efficiency using Forecast Errors}
		\label{NullTestTable}
		\centering 
		\begin{tabular}{llll}
			\hline 
			& SPF CPI          & SPF PCE          & SCE            \\
			\hline 
			\multicolumn{4}{l}{Test 1: Unbiasedness}                                                           \\
			\hline 
			Constant                            & 0.122***         & 0.586***         & 2.220***       \\
			& (0.017)          & (0.061)          & (0.019)        \\
			\hline 
			N                                   & 4697             & 1208             & 67380          \\
			\hline 
			\multicolumn{4}{l}{Test 2: FE does not depend on past information}                                  \\
			\hline 
			Forecast 1-yr before                & 0.307***         & 0.586***         & NA             \\
			& (0.020)          & (0.061)          & NA             \\
			Constant                            & -0.655***        & -0.777***        & NA             \\
			& (0.060)          & (0.116)          & NA             \\
			\hline 
			N                                   & 3429             & 1208             & NA             \\
			$R^2$                 & 0.0721           & 0.118            & NA             \\
			\hline 
			\multicolumn{4}{l}{Test 3: FEs of non-overlapping forecast horizons not serially correlated} \\
			\hline 
			Forecast Error 1-year before        & 0.0756***        & 0.0503***        & NA             \\
			& (0.020)          & (0.035)          & NA             \\
			Constant                            & 0.145***         & 0.275***         & NA             \\
			& (0.021)          & (0.035)          & NA             \\
			\hline 
			N                                   & 3356             & 1208             & NA             \\
			$R^2$                   & 0.00591          & 0.00264          & NA             \\
			\hline 
			\multicolumn{4}{l}{Test 4: Overlapping FEs are only weakly serially correlated}                          \\
			\hline 
			Forecast Error 1-q before           & 0.657***         & 0.834***         & 0.297***       \\
			& (0.025)          & (0.037)          & (0.021)        \\
			Forecast Error 2-q before           & 0.0282           & -0.0858          & 0.308***       \\
			& (0.027)          & (0.048)          & (0.046)        \\
			Forecast Error 3-q before           & -0.0244          & -0.0555          & 0.311***       \\
			& (0.025)          & (0.038)          & (0.045)        \\
			Constant                            & 0.0626***        & 0.113***         & 0.742***       \\
			& (0.019)          & (0.026)          & (0.097)        \\
			\hline 
			N                                   & 2536             & 1004             & 2836           \\
			$R^2$                & 0.439            & 0.552            & 0.232    \\
			\hline      
		\end{tabular}
	\end{table}
	
	The second batch of tests in Table \ref{RevEfficency} focus on estimating forecasting efficiency using revisions of mean forecasts and uncertainty, hereafter referred as revision-based tests.  In plain words, the revision from 1-year-ahead forecast to nowcast of current-year inflation is efficient according two criteria (1) Forecast revision does not depend on past information, including the past revisions. (2) Drop in uncertainy is sufficiently rapid to reflect the uncertainty of all realized shocks. 
	
	The mean revision test by \citet{fuhrer2018intrinsic} takes the following form (using 1 period as an example): 
	
	\begin{eqnarray}\label{RevEffMeanTest}
		y_{i,t+1|t+1} - y_{i,t+1|t}=\alpha + \beta (y_{i,t+1|t} - y_{i,t+1|t-1})+\epsilon_{i,t+1}
	\end{eqnarray}
	
	In the above equation $\beta =0$ according to FIRE, because rational forecast revision only responds to newly realized shocks thus it is not predictable by past revisions.\footnote{Adding $y_{t+1|t}$ to both sides of Equation \ref{RevEffMeanTest} gives an equivalent null hypothesis used by \citet{fuhrer2018intrinsic}: coefficient of regression of $y_{t+1|t+1}$ on  $y_{t+1|t}$ is $1-\beta=1$. }. Since we have four vintages of the forecasts from SPF, the above specification can include lagged revisions up to 4 quarters.  
	
	The test with uncertainty simply replaces the revision of forecast with revision in uncertainty $\sigma^2_{i,t+1|t+1} - \sigma^2_{i.t+1|t}$, for instance. This regression follows from Equation \ref{VarSERv} for SE and Equation \ref{VarNIRv} for NI. Although it  cannot be directly used as a test against FIRE null, the autocorrelation coefficient speaks to the speed of drop in uncertainty. Depending on the model, one can interpret it as the particular structural parameter of rigidity, as shown in Figure \ref{rigidity}. 
	
	Top panel in Table \ref{RevEfficency} and bottom panel presents the results for mean forecast. Following \citet{fuhrer2018intrinsic}, I include median forecast available at time $t$ and $t-1$ as an indicator of past information for the revision regression. In the first column of each panel, I report the regression on a constant. 
	
	What's surprising is the mean revision in forecast being negative and significant. Forecasts on average make downward adjustment of 1.26 percentage points of CPI and  1.1 percentage points of PCE from her previous year forecast of the same-period inflation. 
	
	The second to fourth columns of each panel in Table \ref{RevEfficency} checks auto correlation of revisions including different lags. Revisions of forecasts are serially correlated over 4 quarters and the coefficients are all positive and significant. Also, the median forecasts as the past information always predicts a negative revision with significant coefficients. This is evidence against null hypothesis of FIRE and my estimates are comparable with those by \citet{fuhrer2018intrinsic}. 
	
	In the bottom panel reports auto regression results for revision in uncertainty. Again, the first column first test the mean revision against the null being zero. The mean revisions in uncertainty are both negative(0.5-0.6 percentage poitns equivalence in standard deviation of uncertainty) and statistically significant, confirming our observation from Figure \ref{RevisionHist} that forecasters are more certain about current inflation compared her previous year forecast. 
	
	The second to fourth column show positive serial correlation of revision in uncertainty for both CPI and PCE forecasts. The revision to CPI seems more efficient as serial correlation is with only one quarter lag. For PCE, the revisions in uncertainty are serially correlated with all past three quarters. 
	
	\begin{table}[ht]
		\caption{Tests of Revision Efficiency using Mean Revision and Uncertainty}
		\label{RevEfficency}
		\begin{adjustbox}{angle=90}
			
			\begin{tabular}{lllllllll}
				\hline 
				& \multicolumn{4}{l}{SPF CPI}                     & \multicolumn{4}{l}{SPF PCE}                       \\
				\hline 
				\multicolumn{9}{l}{Test 1.  Revision efficiency of mean forecast}            \\
				\hline 
				& Mean revision & t-1       & t-1- t-2 & t-1-t-3  & Mean revision & t-1       & t-1- t-2  & t-1-t-3   \\
				\hline 
				L.InfExp\_Mean\_rv  &               & 0.539***  & 0.418*** & 0.387*** &               & 0.606***  & 0.435***  & 0.369***  \\
				&               & (0.031)   & (0.043)  & (0.052)  &               & (0.034)   & (0.042)   & (0.049)   \\
				L2.InfExp\_Mean\_rv &               &           & 0.218*** & 0.166**  &               &           & 0.261***  & 0.246***  \\
				&               &           & (0.040)  & (0.053)  &               &           & (0.047)   & (0.058)   \\
				L3.InfExp\_Mean\_rv &               &           &          & 0.134**  &               &           &           & 0.116     \\
				&               &           &          & (0.048)  &               &           &           & (0.069)   \\
				SPFCPI\_ct50        &               & -0.444*** & -0.391** & -0.454** &               &           &           &           \\
				&               & (0.105)   & (0.124)  & (0.138)  &               &           &           &           \\
				SPFPCE\_ct50        &               &           &          &          &               & -0.432*** & -0.413*** & -0.504*** \\
				&               &           &          &          &               & (0.109)   & (0.111)   & (0.138)   \\
				& -1.257***     & 0.329     & 0.351    & 0.546*   & -1.095***     & 0.365     & 0.428*    & 0.641**   \\
				Constant & (0.045)       & (0.191)   & (0.237)  & (0.269)  & (0.039)       & (0.188)   & (0.191)   & (0.228)   \\
				\hline 
				N                   & 1337          & 1045      & 822      & 652      & 1111          & 867       & 683       & 549       \\
				$R^2$                  & 0.000         & 0.335     & 0.355    & 0.372    & 0.000         & 0.409     & 0.444     & 0.452     \\
				\hline 
				\multicolumn{9}{l}{Test 2. Revision efficiency of uncertainty}                                                            \\
				\hline 
				& Mean revision & t-1       & t-1- t-2 & t-1-t-3  & Mean revision & t-1       & t-1- t-2  & t-1-t-3   \\
				\hline 
				L.InfExp\_Var\_rv   &               & 0.290*    & 0.529*** & 0.581*** &               & 0.577***  & 0.477***  & 0.344*    \\
				&               & (0.122)   & (0.117)  & (0.145)  &               & (0.080)   & (0.130)   & (0.148)   \\
				L2.InfExp\_Var\_rv  &               &           & -0.059   & -0.209   &               &           & 0.360*    & 0.205*    \\
				&               &           & (0.125)  & (0.127)  &               &           & (0.143)   & (0.098)   \\
				L3.InfExp\_Var\_rv  &               &           &          & 0.353**  &               &           &           & 0.390*    \\
				&               &           &          & (0.121)  &               &           &           & (0.149)   \\
				Constant              & -0.034***     & -0.011**  & -0.008*  & -0.005   & -0.039***     & -0.019**  & -0.010**  & -0.007*   \\
				& (0.005)       & (0.004)   & (0.003)  & (0.004)  & (0.006)       & (0.006)   & (0.003)   & (0.003)   \\
				\hline 
				N                   & 1189          & 877       & 663      & 504      & 1082          & 801       & 604       & 458       \\
				$R^2$                 & 0.000         & 0.124     & 0.284    & 0.408    & 0.000         & 0.353     & 0.583     & 0.723    \\
				\hline 
			\end{tabular}
		\end{adjustbox}
	\end{table}
	
	
	Table \ref{WeakRevEfficiency} presents the results with the revision replaced with change in mean forecasts and uncertainty, i.e. $y_{t|t-1}$ to $y_{t+1|t}$. The auto-correlation of change in mean forecast and uncertainty does embed  tests of null of FIRE (Equation \ref{VarREPop}). But if the individual forecasts and their uncertainty turn out to be persistent over different horizons, this implies that the agent does not react to the news and newly realized shocks enough. 
	
	
	\begin{table}
		\centering 
		\caption{Weak Tests of Revision Efficiency using Change in Forecasts and Uncertainty}
		\label{WeakRevEfficiency}
		\begin{adjustbox}{width={24cm},totalheight={14cm},angle=90}
			\begin{tabular}{llllllllllllll}
				\hline 
				& \multicolumn{4}{l}{SPF CPI}                     & \multicolumn{4}{l}{SPF PCE}                       &                      & \multicolumn{4}{l}{SCE}                           \\
				\hline 
				\multicolumn{14}{l}{Test 3. Weak revision efficiency of change in forecast}                                                                                                                                    \\
				\hline 
				& Mean change & t-1       & t-1- t-2  & t-1-t-3   & Mean revision & t-1       & t-1- t-2  & t-1-t-3   &                      & Mean revision & t-1       & t-1- t-2  & t-1-t-3   \\
				\hline 
				L.InfExp\_Mean\_ch   &             & -0.295*** & -0.344*** & -0.367*** &               & -0.303*** & -0.348*** & -0.364*** & L.InfExp\_Mean\_ch  &         & -0.433*** & -0.586*** & -0.642*** \\
				&             & (0.034)   & (0.044)   & (0.045)   &               & (0.043)   & (0.059)   & (0.062)   &                    &         & (0.01)     & (0.013)    & (0.025)    \\
				
				L2.InfExp\_Mean\_ch  &             &           & -0.179*** & -0.242*** &               &           & -0.162*   & -0.200**  & L2.InfExp\_Mean\_ch &         &           & -0.336*** & -0.439*** \\
				
				&             &           & (0.047)   & (0.049)   &               &           & (0.061)   & (0.067)   &                                   &         &           & (0.018)    & (0.031)    \\
				L3.InfExp\_Mean\_ch  &             &           &           & -0.097**  &               &           &           & -0.088*   & L3.InfExp\_Mean\_ch &         &           & -0.143*** & -0.270*** \\
				
				&             &           &           & (0.032)   &               &           &           & (0.036)   &                                &         &           & (0.012)    & (0.027)    \\
				
				&             &           &           &           &               &           &           &           & L4.InfExp\_Mean\_ch &         &           &           & -0.183*** \\
				
				&             &           &           &           &               &           &           &           &                                 &         &           &           & (0.027)    \\
				&             &           &           &           &               &           &           &           & L5.InfExp\_Mean\_ch &         &           &           & -0.096*** \\
				&             &           &           &           &               &           &           &           &                      &         &           &           & (0.021)    \\
				&             &           &           &           &               &           &           &           & L6.InfExp\_Mean\_ch &         &           &           & -0.044**  \\
				&             &           &           &           &               &           &           &           &                                     &         &           &           & (0.013)    \\
				Constant               & -0.005      & -0.004    & -0.011    & -0.015    & 0.001         & 0.008     & -0.002    & -0.007    & Constant              & -0.055* & -0.034    & -0.001    & -0.002    \\
				& (0.023)     & (0.024)   & (0.026)   & (0.026)   & (0.020)       & (0.020)   & (0.022)   & (0.022)   &                                 & -0.023  & -0.023    & -0.028    & -0.033    \\
				\hline 
				N                    & 1636        & 1430      & 1266      & 1141      & 1402          & 1190      & 1022      & 898       & N                   & 53016   & 43166     & 28850     & 14445     \\
				$R^2$                  & 0.000       & 0.086     & 0.112     & 0.128     & 0.000         & 0.090     & 0.112     & 0.120     & $R^2$ &  0.000       & 0.202     & 0.273     & 0.306   \\
				\hline 
				\multicolumn{14}{l}{Test 4. Weak revision efficiency of change in uncertainty}                \\
				\hline                                                                                                                 
				& Mean change & t-1       & t-1- t-2  & t-1-t-3   & Mean change   & t-1       & t-1- t-2  & t-1-t-3   &                      & Mean change   & t-1       & t-1- t-2  & t-1-t-3   \\
				\hline 
				L.InfExp\_Var\_ch    &             & -0.393**  & -0.568*** & -0.543**  &               & -0.444*** & -0.602*** & -0.658*** & L.InfExp\_Var\_ch    &               & -0.382*** & -0.565*** & -0.652*** \\
				&             & (0.136)   & (0.146)   & (0.177)   &               & (0.094)   & (0.127)   & (0.145)   &                      &               & -0.015    & -0.022    & -0.037    \\
				L2.InfExp\_Var\_ch   &             &           & -0.322**  & -0.278*   &               &           & -0.289*   & -0.404**  & L2.InfExp\_Var\_ch   &               &           & -0.300*** & -0.406*** \\
				&             &           & (0.104)   & (0.132)   &               &           & (0.110)   & (0.137)   &                      &               &           & -0.021    & -0.031    \\
				L3.InfExp\_Var\_ch   &             &           &           & 0.048     &               &           &           & -0.292    & L3.InfExp\_Var\_ch   &               &           & -0.123*** & -0.265*** \\
				&             &           &           & (0.096)   &               &           &           & (0.154)   &                      &               &           & -0.012    & -0.027    \\
				&             &           &           &           &               &           &           &           & L4.InfExp\_Var\_ch   &               &           &           & -0.130*** \\
				&             &           &           &           &               &           &           &           &                      &               &           &           & -0.025    \\
				&             &           &           &           &               &           &           &           & L5.InfExp\_Var\_ch   &               &           &           & -0.058**  \\
				&             &           &           &           &               &           &           &           &                      &               &           &           & -0.018    \\
				&             &           &           &           &               &           &           &           & L6.InfExp\_Var\_ch   &               &           &           & -0.025    \\
				&             &           &           &           &               &           &           &           &                      &               &           &           & -0.012    \\
				Constant               & -0.002      & -0.001    & 0.004     & 0.004     & 0.000         & 0.002     & 0.004     & 0.005     &   Constant                   & -1.339***     & -1.324*** & -1.139*** & -0.839*** \\
				& (0.005)     & (0.005)   & (0.004)   & (0.004)   & (0.004)       & (0.004)   & (0.004)   & (0.004)   &                      & -0.123        & -0.11     & -0.104    & -0.163    \\
				\hline 
				N                    & 1202        & 950       & 765       & 625       & 1078          & 842       & 657       & 519       &                      & 53016         & 43166     & 28850     & 14445     \\
				$R^2$ & 0.000       & 0.120     & 0.265     & 0.242     & 0.000         & 0.233     & 0.321     & 0.385     &                      & 0             & 0.182     & 0.278     & 0.321  \\
				\hline    
			\end{tabular}
		\end{adjustbox}
	\end{table}
	
	\section{Shock-based tests of expectation rigidity }\label{IRShocks}
	
	\citet{coibion2012can} explores the implications of expectation rigidity models using externally identified shocks to inflation.  Unlike the time series regressions that test null hypotheses of FIRE in previous section, this approach allows a more straightforward comparison between the empirical evidence from surveys and the theoretical predictions illustrated in Figure \ref{ir_pop}. The difficulty of this approach lies in identifying a shock $\omega_t$ that is a pure innovation to inflation at time $t$. 
	
	In this paper I use three types of shocks: technology shock from \citet{gali1999technology}, oil price shock from \citet{hamilton1996happened} and monetary policy shocks from  \citet{laseen2011anticipated}. The first two are the same in \citet{coibion2012can}. \footnote{ Another shock in \citet{coibon2012can} is the news shock by \citet{barsky2011news}. This will be included in later version of the paper.} 
	
	
	(1) Technology shock is identified from a three variate structural vector autoregression(SVAR) model  (output per capita, hours and inflation) by imposing a widely used long-run restriction that non-technology shocks have no long-run output impacts. Based on Bayes information criterion, I use the lag of 4 quarters as in \citet{coibion2012can} \footnote{A recent alternative to long-run restriction approach is the ``max-share approach'' developed by \citet{francis2014flexible}. It is shown to have better small-sample properties. In particular,  the approach defines technology shock as the variation of current period labor productivity (output per hour) that explains the maximum fraction of future labor productivity over an exogenously determined horizon. The results using this shock will be included in a later version of the paper. For the replication purpose now, I stay with \citet{gali1999technology}}. The sample period used to identify the shock is 1949-2019, while the period where it enters my analysis is the same to the period of survey data: 2007-2019 for SPF and 2013-2019 for SCE. 
	
	(2) Oil price shock in each period is defined as the maximum of log change in crude oil prices over the past 1-year and 0. Therefore it is bounded zero.\footnote{The series of oil price is Spot Crude Oil Price: West Texas Intermediate (WTI).}
	
	(3) Monetary policy shocks: target surprise and path surprise in the terminology of \citet{laseen2011anticipated}. Target surprise is defined as unexpected change in federal funds rate in a particular date of FOMC meetings. It is the OLS residual of federal funds rate change in the past expected change in federal funds rate. The 2-year ahead path surprise is the regression residual of future implied federal funds rate on the target surprise. Depending on the frequency of the data being monthly or quarterly, I take the sum of all the changes within each period.   
	
	The reason for including monetary policy shocks, although it turns out to provide less robust evidence, is twofold. First, it is well known that the role of expectation in the working and implementation of monetary policy in the post criss period has been of a great relevance. Especially, around zero-lower-bound, the central banks have utilized nontraditional tools such as forward guidance which primarily works through influencing expectations of market agents. 
	
	In Figure \ref{Inflationshocks}, all four shocks are plotted in quarterly between 1985-2019. All shocks are normalized by its respective sample standard deviations. 
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=12cm]{figures/inf_shocksQ.png}
		\caption{ Shocks to Inflation}
		\label{Inflationshocks}
	\end{figure}
	
	\subsection{Replicating \citet{coibion2012can}}
	
	For a direct comparison of my results and \citet{coibion2012can}, I first explore the impulse responses of CPI inflation $y_{t+k}$, SPF forecast errors and disagreements to one standard deviation of each shock at time $t$. In particular, the responses of disagreements is with respect to the absolute value of the shocks. Because CPI inflation forecast is available only after 1984, the sample period 1984-2007 is six years shorter than that in Figure 2 from \citet{coibion2012can}: 1976-2007. I do not include the results for PCE inflation as there is no PCE forecast during this period. 
	
	The underlying regression that produces impulse response estimates is  Equation \ref{IRRegression}, according to which inflation(or moments) in current quarter is a function of 4-period lags of itself  and the realized shocks in current and previous period. The estimate of autoregression coefficients $\beta_\tau$ and shock-specific coefficients $\beta_{S,k}$ for different lags can be used to compute impulse responses of the variables of interest. In the impulse response graph, standard errors are computed using the parametric bootstrapping approach as in \citet{coibion2012can}. 
	
	\begin{eqnarray}\label{IRRegression}
		y_{t}  = \alpha + \sum^4_{\tau=1} \beta_{\tau} y_{t-\tau} +  \sum^1_{k=0} \sum_{S \in \{O,T\}}\beta_{S,k}\omega_{S,t-k} + \epsilon_t 
	\end{eqnarray}
	
	FIRE predicts $\beta_{S,k}=0\quad \forall k=1$ for the regressions with forecasts moments as dependent variable. i.e. forecasts react only to contemporaneous shocks instantaneously. Therefore, the average FE should not be dependent upon past shocks and  only experience a one-time rise and return zero immediately. The disagreements will not respond to the shock at all. 
	
	The results  presented in the left panel of the Figure \ref{ReplicateCoibionBefore2007} are consistent with FIRE predictions. Responses to productivity and oil price shocks are broadly consistent with \citet{coibion2012can} despite a wider confidence band possibly due to the change in inflation measures and difference in sample period. First, one standard deviation of productivity unsurprisingly brings down headline inflation by around 10 percentage points  in the first quarter and the negative impacts gradually mute since then till the 7-th quarter. Oil price shock of one standard deviation increases headline inflation by around 3 percentage points in the first quarter and the inflationary impacts last for 6 quarters. PCE inflation responds to both the shocks in a similar manner with slightly different magnitudes. The responses coefficients are statistically significant as the $95\%$ confidence interval stays on one side of zero for both shock for the same period. 
	
	Second, population forecast errors respond to shocks in a sluggish manner as predicted in rigidity models. This is illustrated using both SPF's FE of CPI in the second graph of  left panel in Figure \ref{ReplicateCoibionBefore2007}. As we define the forecast error as point forecast minus realized value, forecast error rises(drops) after a positive(negative) shock and gradually return to zero around 4-5th quarters after the shock. 
	
	Lastly, SE and NI models imply disagreement pick up after shocks and gradually drop over longer horizon.  Looking into the graph, the average response of Disg to absolute value of  technology and oil shocks exhibit patterns similar to this prediction. Note now that the initial response is no longer statistically significant(same as the original result) and the pick-up of disagreement after both shocks do not take place immediately in the same quarter but in one quarter after the shock. \footnote{In addition, the degree of long-run disagreements sheds light upon one subtle difference between the SE and NI. Disagreements always exist in NI with the presence of private signals , in contrast, disagreement is zero over the long run in SE. }
	
	The responses to monetary policy shocks turn out to be nosier than for technology and oil price shocks, as presented in the right panel of Figure \ref{ReplicateCoibionBefore2007}. On the top, I first plot the impulse response of inflation to path surprises $ED8ut$ and target surprise $MP1ut$, separately. On average, inflation reduces by around 10 percentage points after one unit increase of target surprise and increases by 10 percentage points following one unit of path surprise to federal funds rate. Both responses are  statistically significant in $10\%$  level. The unexpected future tightening causing a rise in inflation is consistent with the literature of price puzzle. \footnote{See \cite{nakamura2018high} as an example of inflationary responses to a monetary tightening move of the Fed.}
	
	In the middle figure presents the responses of CPI forecast errors by SPF.  Although the average response seems to go in the same direction of the respective monetary shocks, consistent with the pattern seen for technology and oil price shocks, none of the responses are statistically significant and the estimates have big standard errors of 10-20 percentage points.  
	
	Similarly, the responses of disagreements to both monetary policy shocks in the bottom panel are not statistically significant throughout the 10 quarters.  
	
	How do we interpret the finding of non-response of forecasting errror and disagreements to monetary policy shocks in the context of rigidity models? Non-response of FE suggests that on average professional forecasters have incorporated the monetary policy changes in their forecasts. Non-response of disagreements could be due to that forecasters ``agree'' on the realization of monetary policy shocks. Although the benchmark theory of SE and NI do not differentiate shocks, the evidence here seems to suggest that the degree of rigidity depends on  nature of the shocks. 
	
	Or there are other explanations.  First, overall the monetary policy shocks contribute only a small part of variation in inflation compared to supply shocks. This was actually used by \cite{coibion2012can} to justify why monetary policy shock was not used in their exercise.  Second,  I am just running into the same difficulty in identifying real impacts of monetary policy shocks from low frequency data as all other papers addressing this issue. \footnote{Examples of identifying monetary policy shocks. \cite{xxx} } 
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=7cm,totalheight=3cm]{figures/CPIAU_ashocks_nmp_before2007.png}  
		\includegraphics[width=7cm,totalheight=3cm]{figures/CPIAU_ashocks_before2007.png} \\
		\smallskip
		\includegraphics[width=7cm,totalheight=3cm]{figures/SPFFE_ashocks_nmp_before2007.png} 
		\includegraphics[width=7cm,totalheight=3cm]{figures/SPFFE_ashocks_before2007.png} \\
		\smallskip
		\includegraphics[width=7cm,totalheight=3cm]{figures/SPFDisg_ab_ashocks_nmp_before2007.png} 
		\includegraphics[width=7cm,totalheight=3cm]{figures/SPFDisg_ab_ashocks_before2007.png} 
		\caption{Responses of Inflation and Professional Forecast Moments: 1984-2007}
		\label{ReplicateCoibionBefore2007}
	\end{figure}
	
	
	\subsection{Additional evidence from uncertainty}
	
	In Figure \ref{ReplicateCoibionwholeperiod}, I extend the sample period to include the post-2007 years till 2019. Importantly, post2007 is the period when SPF starts surveying density forecasts that allow us to study the dynamics of uncertainty. In addition, the post crisis period has been characterized by a number of different features in terms of the behavior of macroeconomy(i.e. persistently low inflation) and monetary policy implementation (i.e. emphasis on monetary policy communication and zero lower bound), therefore it is worth examining if the patterns documented by \cite{coibion2012can} remain for the entire period. Also, since PCE inflation forecast is not available until 2007, I report results for both CPI and PCE as in previous analysis. 
	
	The left panel of  Figure \ref{ReplicateCoibionwholeperiod} presents impulse responses of average uncertainty of SPF in addition to that inflation, forecast error, disagreements in response to technology and oil price shocks. As shown in the top three figures, the results are consistent with that in Figure \ref{ReplicateCoibionBefore2007} for period before 2007.  Oil shock(technology shock) increases(decreases) inflation in the first quarter by 10 percentage  points, whose impacts last till 7-8th quarters. Confidence interval of the responses is smaller compared to previous figure probably due to larger sample size.  Average forecast errors react partially to the shock and gradually return to zero over the 4-5th quarters afterward. Disagreements picked up in the second quarter and return to zero 2 or 3 quarters  later. 
	
	
	The primary focus of this paper is the behavior of uncertainty. Its responses to the absolute value of various shocks is presented in the bottom of the panel. Since  average uncertainty do not directly depend on the realizations and sizes of the shocks in various models, as shown in Equation \ref{VarREEq}  Equation \ref{VarSEPop}, and Equation \ref{VarNIEq}, the response of uncertainty cannot be used as a screening device of  FIRE and rigidity models. Instead, it should be taken as a basic consistency check of different theories with respect to the behavior of uncertainty.  
	
	The response graph seems consistent with this simple prediction, except for the uncertainty about CPI in responses to oil price shock. The responses of average uncertainty is not significantly different from zero throughout 10 quarters. \footnote{The impulse response that provides direct checking of rigidity models versus FIRE is the responses of revision in uncertainty, i.e. uncertainty about inflation in $t+h$ at time $t$ relative to $t-1$, $t-2$, etc. The results will be presented in a revised version of the paper.} 
	
	Impacts of monetary policies are shown in the right panel of Figure \ref{ReplicateCoibionwholeperiod}. Path surprise to federal funds rate, i.e. future monetary policy stances, again brings about the inflationary effect as before. One standard deviation of true tightening shock increases headline CPI inflation by around 15 percentage points in the first period.  In the same time, unexpected rate change does not affect inflation significantly once we include the post-2007 period.  One possible explanation for this is the small variation of target surprise after financial crisis, as illustrated in Figure \ref{Inflationshocks}. Except for the dramatic monetary loosening during financial crisis, there was little variation in the unexpected federal fund rate change.  
	
	Similar to results for pre-2007 period, the initial response of average forecast error to future tightening shock is statistically significant in the first period but insignificant soon after.  Interestingly, even though the target surprise does not affect inflation itself, forecast errors do react to it in an inflationary manner. The magnitude of the response is as large as 25 percentage points in the first quarter. Rigidity models predict forecast errors depend on past shocks, while there does not seem to be strong evidence for this when it comes to monetary policy shocks. Forecasters reaction to monetary policy shocks appear to more efficient than for supply shocks. 
	
	Disagreements show little response to monetary policy shocks as well, with the only exception being PCE forecast with respect to path surprise. The estimates of these responses are not  significantly from zero throughout the entire horizon. Non-response of disagreements could arise if forecasters have incorporated the monetary policy shocks (thus the shock no longer qualified as a ``shock'') , or all forecasters simultaneously incorporating the realization of the monetary shocks. In the context of NI model, the disagreements can only arise with the presence of private signals. Therefore, monetary policy being a more public signal can help explain the muted response of disagreements in comparison of the other shocks. \footnote{Another explanation is that monetary policy actually coordinates agents' expectations, thus accordingly reduce disagreements, according to \citet{morris2002social}. This mechanism can mute the response of disagreements.}
	
	Lastly, average uncertainty do not react to monetary policy shocks in the extended period. None of the response is significantly different from zero. This is the same with technology and oil price shocks. 
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=7cm]{figures/Inf_ashocks_nmp.png}  
		\includegraphics[width=7cm]{figures/Inf_ashocks.png} \\
		\smallskip
		\includegraphics[width=7cm]{figures/SPFFE_ashocks_nmp.png} 
		\includegraphics[width=7cm]{figures/SPFFE_ashocks.png} \\
		\smallskip
		\includegraphics[width=7cm]{figures/SPFDisg_ab_ashocks_nmp.png} 
		\includegraphics[width=7cm]{figures/SPFDisg_ab_ashocks.png} \\
		\smallskip 
		\includegraphics[width=7cm]{figures/SPFVar_ab_ashocks_nmp.png} 
		\includegraphics[width=7cm]{figures/SPFVar_ab_ashocks.png} 
		\caption{Responses of Inflation and Professional Forecast Moments: 1984-2019}
		\label{ReplicateCoibionwholeperiod}
	\end{figure}
	
	
	\subsection{Evidence from households}
	
	It is widely documented in the literature that behaviors of households expectations more idiosyncratic in comparison with that of professional forecasters. \footnote{For this reason, \cite{carroll2003macroeconomic}, for instance, use median professional forecasts as to approximate ``rational'' forecasts.} This section extends the impulse responses estimation of externally identified shocks to the household forecasts moments of SCE.  The monthly data of SCE allows an analysis in a higher frequency but for a shorter period 2013-2019. 
	
	As technology shock can only be recovered from quarterly time series of output, I only present results using oil price shock and monetary policy shocks in Figure \ref{SCE_IR}. The responses to oil price shocks, target surprise and path surprise are plotted in column 1, 2 and 3, respectively. 
	
	Oil price shock increases CPI by  7-8 percentage points in the first period and the impacts last over the entire 10 months. This is not surprising from the previous results on quarterly data. 
	
	Estimated in higher frequency, the response to target surprise is on average 2.5 percentage points and statistically significant in $10\%$ level. This confirms the wide practice of the literature that identifies monetary non-neutrality using high frequency data. In contrast, the inflation responses to path surprise is not significant. 
	
	As to the households forecast, the starkly wider confidence band across  shocks and moments seen in Figure \ref{SCE_IR} are not that surprising given the wide dispersion of the forecasts moments of a dramatically larger magnitude seen in Figure \ref{UnceratitnyOtherMoments}.  
	
	One of the major patterns arising here is that there is no notable difference in responses to oil price shock versus monetary policy shocks, as seen in professional forecasters.  Average forecast errors react to none of these shocks and neither do disagreements and uncertainty.  
	
	One interesting exception is the response of disagreements to oil price changes. Households' disagreements concerning inflation drop by 1 percentage point in the first period after an oil price shock and the response has a reasonably small standard error. The drop only lasts for 1 month and immediately return to zero since then. This suggests that households are digesting the shock in an efficient manner.  
	
	It is widely conjectured (in spite of limited evidence) that salient items such as gasoline price plays an important role in affecting household inflation expectation. The evidence presented here seems to be consistent with such a prediction. 
	
	
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=3cm,height=2cm]{figures/CPIAU_ashocks_nmpM.png}  
		\includegraphics[width=6cm,height=2cm]{figures/CPIAU_ashocksM.png} \\
		\smallskip
		\includegraphics[width=3cm,height=2cm]{figures/SCEFE_ashocks_nmpM.png} 
		\includegraphics[width=6cm,height=2cm]{figures/SCEFE_ashocksM.png} \\
		\smallskip
		\includegraphics[width=3cm,height=2cm]{figures/SCEDisg_ab_ashocks_nmpM.png} 
		\includegraphics[width=6cm,height=2cm]{figures/SCEDisg_ab_ashocksM.png} \\
		\smallskip 
		\includegraphics[width=3cm,height=2cm]{figures/SCEVar_ab_ashocks_nmpM.png} 
		\includegraphics[width=6cm,height=2cm]{figures/SCEVar_ab_ashocksM.png} 
		\caption{ Responses of Inflation and Household Forecast Moments: 2013-2019}
		\label{SCE_IR}
	\end{figure}
	
	\subsection{Discussion of the results and next step}
	
	This section presents one major additional insight in addition to \cite{coibion2012can}: expectation rigidity is dependent on the type of shock. In particular, professional forecasters are slow in digesting oil and technology shock to resolve disagreements and reduce forecast error while react to monetary policy shocks relatively more efficient. This is the easiest seen in the non-response or instantaneous response if any of forecast error and disagreements to monetary policy shocks. The similar can be said for households, in contrast, for oil price shock instead of monetary policy shocks.
	
	Shock-dependent rigidity is not a default feature in the benchmark rigidity models such as SE and NI, i.e. $\omega_t$ in Equation \ref{AR_process}. It is true that the distinction of public and private signals within NI provides one possibility of reconciling difference in response to shocks.  If we interpret different ``shocks'' considered here as noisy signals instead of shocks to fundamental variable as defined in \ref{AR_process}, then the difference across ``shocks'' in their degree of publicity may account for the difference in rigidity.  But this implicitly implies redefining the  framework presented in this paper. 
	
	Moreover, the finding that average uncertainty of fixing horizon by forecasters and households do not react to all the shocks is consistent with the current framework although it does not differentiate rigidity models from FIRE benchmark.  
	
	Efficient revision implies  uncertainty drop as much as the volatility of the shock as one approach the terminate date. Given the volatility of of different shock are different, this provides the possibility of identifying rigidity by directly comparing the observed revision in uncertainty and that is consistent with the volatility of the shock. This will be the next step of the analysis.  
	
	\section{Conclusion}
	
	In summary, three major conclusions can be drawn from this paper.  First, full information rational expectation implicitly assumes agents share the common information and agree on the model that generates the data. Therefore, agents do not only agree on the mean forecast of a macroeconomic variable but also share the same degree of uncertainty. The empirical dispersion of individual uncertainty in future inflation seems to be inconsistent with this simple prediction. 
	
	Second, rigidity of expectation from either inattention or under-reaction due to noisiness of the signals imply agents do not revise forecasts as efficiently as they do in FIRE in the face of new information. This can be seen from both a sluggish pattern of forecast revision or uncertainty reduction across different vintages of the forecast. A weaker test of this spirit uses change of forecasts with fixed horizon. These tests support rigidity models in addition to other null hypotheses of rational expectation including unbiasedness,  non-serial-correlation of forecast error. etc.
	
	Lastly, the directly estimated response of households and professional forecasters' expectation to shocks to inflation suggest that rigidity differs across the shocks. In particular, professional forecasters are more responsive to monetary policy shocks and households are more responsive to oil price shocks. This motivates next-step analysis of how much resolution of uncertainty can be attributed to the volatility of various shocks. This shows the use of uncertainty.
	
	So far, the dynamics of moments are separately estimated for each moment. Therefore, as a natural extension of the current analysis, one can  undertake a generalized method of moment (GMM) estimation that simultaneously utilize multi-moment restrictions to recover a better estimate of the rigidity parameters.  This will provide a better parameter that can be used in structural macro models that build in rigidity of expectations. 
	
	\bibliographystyle{apalike}
	\bibliography{TestingExpectationTheories}
	
\end{document}
